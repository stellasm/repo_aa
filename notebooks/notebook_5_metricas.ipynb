{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_actual, y_predicted, positive_label, show=True):\n",
    "    # Construye una matriz de confusión (binaria)\n",
    "    # y_actual es la secuencia de etiquetas reales\n",
    "    # y_predicted es la secuencia de etiquetas predichas por el clasificador\n",
    "    # positive_label indica cuál es la etiqueta considerada positiva.\n",
    "    n = len(y_actual)\n",
    "\n",
    "    tp =0   # verdaderos positivos\n",
    "    tn =0   # verdaderos negativos\n",
    "    fp = 0  # falsos positivos\n",
    "    fn = 0  # falsos negativos\n",
    "    \n",
    "    for i in range(n):\n",
    "        if y_actual[i] == 'spam' and y_pred[i] == 'spam':\n",
    "            tp = tp + 1\n",
    "        if y_actual[i] == 'spam' and y_pred[i] == 'no-spam':\n",
    "            fn = fn + 1\n",
    "        if y_actual[i] == 'no-spam' and y_pred[i] == 'no-spam':\n",
    "            tn = tn + 1\n",
    "        if y_actual[i] == 'no-spam' and y_pred[i] == 'spam':\n",
    "            fp = fp + 1\n",
    "    \n",
    "    \n",
    "    if show:\n",
    "        display(pd.DataFrame([[tp, tn], [fp, fn]], index=[\"real +\", \"real -\"], columns=[\"pred +\", \"pred -\"]))\n",
    "        \n",
    "        \n",
    "    return tp, tn, fp, fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred +</th>\n",
       "      <th>pred -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real +</th>\n",
       "      <td>2</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real -</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred +  pred -\n",
       "real +       2     958\n",
       "real -      20      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1\n",
      "(tp, tn, fp, fn) =  (2, 958, 20, 10)\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "y_actual = [\"spam\"] * 10 + [\"no-spam\"] * 978 + [\"spam\"] * 2\n",
    "y_pred = [\"spam\"] * 2 + [\"no-spam\"] * 900 + [\"spam\"] * 20 + [\"no-spam\"] * 68\n",
    "tp, tn, fp, fn = confusion_matrix(y_actual=y_actual, y_predicted=y_pred, positive_label=\"spam\")\n",
    "\n",
    "print(\"Test 1\")\n",
    "print(\"(tp, tn, fp, fn) = \", (tp, tn, fp, fn))\n",
    "assert((tp, tn, fp, fn) == (2, 958, 20, 10))\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Métricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(tp, tn, fp, fn):\n",
    "    accuracy = (tp+tn)/n\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def precision_score(tp, tn, fp, fn):\n",
    "    prec = tp / (tp + fp)\n",
    "    return prec\n",
    "\n",
    "\n",
    "def recall_score(tp, tn, fp, fn):\n",
    "    recl = tp / (tp + fn)\n",
    "    return recl\n",
    "\n",
    "\n",
    "def f_beta_score(tp, tn, fp, fn, beta):\n",
    "    prec = precision_score(tp, tn, fp, fn)\n",
    "    recl = recall_score(tp, tn, fp, fn)\n",
    "    f_beta = (1+ beta ** 2)* prec * recl / (recl + prec * beta ** 2)\n",
    "    return f_beta\n",
    "\n",
    "\n",
    "def f1_score(tp, tn, fp, fn):\n",
    "    return f_beta_score(tp, tn, fp, fn, beta=1)\n",
    "\n",
    "\n",
    "def all_metrics(tp, tn, fp, fn):\n",
    "    accuracy = round(accuracy_score(tp, tn, fp, fn), 3)\n",
    "    precision = round(precision_score(tp, tn, fp, fn), 3)\n",
    "    recall = round(recall_score(tp, tn, fp, fn), 3)\n",
    "    f1 = round(f1_score(tp, tn, fp, fn), 3)\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred +</th>\n",
       "      <th>pred -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real +</th>\n",
       "      <td>2</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real -</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred +  pred -\n",
       "real +       2     958\n",
       "real -      20      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2\n",
      "(accuracy, precision, recall, f1) =  (0.97, 0.091, 0.167, 0.118)\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "tp, tn, fp, fn = confusion_matrix(y_actual=y_actual, y_predicted=y_pred, positive_label=\"spam\")\n",
    "(accuracy, precision, recall, f1) = all_metrics(tp, tn, fp, fn)\n",
    "\n",
    "print(\"Test 2\")\n",
    "print(\"(accuracy, precision, recall, f1) = \", (accuracy, precision, recall, f1))\n",
    "assert((accuracy, precision, recall, f1) == (0.97, 0.091, 0.167, 0.118))\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred +</th>\n",
       "      <th>pred -</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real +</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real -</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred +  pred -\n",
       "real +       0       0\n",
       "real -       0       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0225fef07d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_actual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_actual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gato\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_actual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_actual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gato\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-8713b9116d5f>\u001b[0m in \u001b[0;36mall_metrics\u001b[0;34m(tp, tn, fp, fn)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-8713b9116d5f>\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(tp, tn, fp, fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Etiquetas reales\n",
    "y_actual = [\"perro\"] * 18 + [\"gato\"] * 980 + [\"perro\"] * 5\n",
    "\n",
    "# Etiquetas devueltas por \"clasificador A\"\n",
    "y_pred_1 = [\"gato\"] * 980 + [\"perro\"] * 20 + [\"gato\"] * 3\n",
    "\n",
    "# Etiquetas devueltas por \"clasificador B\"\n",
    "y_pred_2 = [\"perro\"] * 40 + [\"gato\"] * 900 + [\"perro\"] * 60 + [\"gato\"] * 3\n",
    "\n",
    "res = []\n",
    "tp, tn, fp, fn = confusion_matrix(y_actual=y_actual, y_predicted=y_pred_1, positive_label=\"gato\", show=True)\n",
    "res.append(all_metrics(tp, tn, fp, fn))\n",
    "\n",
    "tp, tn, fp, fn = confusion_matrix(y_actual=y_actual, y_predicted=y_pred_1, positive_label=\"gato\", show=True)\n",
    "res.append(all_metrics(tp, tn, fp, fn))\n",
    "\n",
    "tp, tn, fp, fn = confusion_matrix(y_actual=y_actual, y_predicted=y_pred_1, positive_label=\"perro\", show=True)\n",
    "res.append(all_metrics(tp, tn, fp, fn))\n",
    "\n",
    "tp, tn, fp, fn = confusion_matrix(y_actual=y_actual, y_predicted=y_pred_1, positive_label=\"perro\", show=True)\n",
    "res.append(all_metrics(tp, tn, fp, fn))\n",
    "\n",
    "pd.DataFrame(res, columns=[\"accuracy\", \"precision\", \"recall\", \"f1\"], index=[\"CLF A (gato)\", \"CLF B (gato)\", \"CLF A (perro)\", \"CLF B (gato)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5e05f65292ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_actual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_actual_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"perro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mf1_gato\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mf1_perro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mf1_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf1_gato\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf1_perro\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-86ec4873df94>\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(tp, tn, fp, fn)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf_beta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-86ec4873df94>\u001b[0m in \u001b[0;36mf_beta_score\u001b[0;34m(tp, tn, fp, fn, beta)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf_beta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mrecl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mf_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mprec\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecl\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrecl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprec\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-86ec4873df94>\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(tp, tn, fp, fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2131efe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "y_actual = [\"perro\"] * 100 + [\"gato\"] * 900 + [\"perro\"] * 80\n",
    "y_pred =   [\"perro\"] * 80 + [\"gato\"] * 800 + [\"perro\"] * 200\n",
    "\n",
    "tns_gato = []\n",
    "f1s_gato = []\n",
    "f1s_perro = []\n",
    "f1s_avg = []\n",
    "\n",
    "\n",
    "for i in range(0, 10000, 100):\n",
    "    y_actual_2 = y_actual + [\"perro\"] * i\n",
    "    y_pred_2 = y_pred + [\"perro\"] * i\n",
    "\n",
    "    tp1, tn1, fp1, fn1 = confusion_matrix(y_actual=y_actual_2, y_predicted=y_pred_2, positive_label=\"gato\")\n",
    "    tp2, tn2, fp2, fn2 = confusion_matrix(y_actual=y_actual_2, y_predicted=y_pred_2, positive_label=\"perro\")\n",
    "\n",
    "    f1_gato = f1_score(tp1, tn1, fp1, fn1)\n",
    "    f1_perro = f1_score(tp2, tn2, fp2, fn2)\n",
    "    f1_avg = (f1_gato + f1_perro) / 2\n",
    "\n",
    "    tns_gato.append(tn1)\n",
    "    f1s_gato.append(f1_gato)\n",
    "    f1s_perro.append(f1_perro)\n",
    "    f1s_avg.append(f1_avg)\n",
    "\n",
    "plt.plot(tns_gato, f1s_gato, \"*-\", label=\"f1_gato\")\n",
    "plt.plot(tns_gato, f1s_perro, \"o-\", label=\"f1_perro\")\n",
    "plt.plot(tns_gato, f1s_avg, \"x-\", label=\"f1_avg\")\n",
    "plt.xlabel(\"True Negatives (Gato)\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.ylim([0.5,1])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
