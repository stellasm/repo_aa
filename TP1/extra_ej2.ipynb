{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stella/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import sklearn.pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.491390</td>\n",
       "      <td>0.164441</td>\n",
       "      <td>1.231538</td>\n",
       "      <td>1.242870</td>\n",
       "      <td>1.557584</td>\n",
       "      <td>0.045490</td>\n",
       "      <td>0.130215</td>\n",
       "      <td>-0.434351</td>\n",
       "      <td>1.608691</td>\n",
       "      <td>-0.275786</td>\n",
       "      <td>...</td>\n",
       "      <td>1.495644</td>\n",
       "      <td>0.386186</td>\n",
       "      <td>-1.085902</td>\n",
       "      <td>-1.198301</td>\n",
       "      <td>-0.011830</td>\n",
       "      <td>1.537544</td>\n",
       "      <td>-0.772709</td>\n",
       "      <td>-0.140069</td>\n",
       "      <td>2.087113</td>\n",
       "      <td>-0.831155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.274878</td>\n",
       "      <td>0.278034</td>\n",
       "      <td>-1.310784</td>\n",
       "      <td>0.680072</td>\n",
       "      <td>-0.550258</td>\n",
       "      <td>0.635943</td>\n",
       "      <td>-0.447771</td>\n",
       "      <td>1.612193</td>\n",
       "      <td>0.523218</td>\n",
       "      <td>-0.817668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029643</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>-0.682538</td>\n",
       "      <td>1.218986</td>\n",
       "      <td>-0.318957</td>\n",
       "      <td>-0.644568</td>\n",
       "      <td>-0.006130</td>\n",
       "      <td>-1.237353</td>\n",
       "      <td>-1.329079</td>\n",
       "      <td>-1.326488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.224313</td>\n",
       "      <td>-0.570958</td>\n",
       "      <td>-0.271176</td>\n",
       "      <td>-0.132801</td>\n",
       "      <td>-1.004479</td>\n",
       "      <td>0.931530</td>\n",
       "      <td>-1.450683</td>\n",
       "      <td>-1.708992</td>\n",
       "      <td>-0.448392</td>\n",
       "      <td>-2.122299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058687</td>\n",
       "      <td>-2.443076</td>\n",
       "      <td>1.984582</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>0.142990</td>\n",
       "      <td>-0.198892</td>\n",
       "      <td>-0.039329</td>\n",
       "      <td>-0.586616</td>\n",
       "      <td>2.250676</td>\n",
       "      <td>1.492455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.585318</td>\n",
       "      <td>-0.853202</td>\n",
       "      <td>-0.272304</td>\n",
       "      <td>-0.549254</td>\n",
       "      <td>-2.982352</td>\n",
       "      <td>-0.169744</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.415619</td>\n",
       "      <td>-0.383416</td>\n",
       "      <td>0.874080</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.187086</td>\n",
       "      <td>-0.379730</td>\n",
       "      <td>0.287214</td>\n",
       "      <td>1.648818</td>\n",
       "      <td>-0.736264</td>\n",
       "      <td>-0.886601</td>\n",
       "      <td>-1.271747</td>\n",
       "      <td>-0.149291</td>\n",
       "      <td>0.200660</td>\n",
       "      <td>-1.481958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.415519</td>\n",
       "      <td>1.418729</td>\n",
       "      <td>0.602669</td>\n",
       "      <td>-0.799339</td>\n",
       "      <td>0.293878</td>\n",
       "      <td>-0.179589</td>\n",
       "      <td>-0.713989</td>\n",
       "      <td>-0.148405</td>\n",
       "      <td>0.023052</td>\n",
       "      <td>0.426702</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.730989</td>\n",
       "      <td>-0.470786</td>\n",
       "      <td>-0.893196</td>\n",
       "      <td>1.131444</td>\n",
       "      <td>-0.423028</td>\n",
       "      <td>-0.268517</td>\n",
       "      <td>0.304515</td>\n",
       "      <td>-1.224529</td>\n",
       "      <td>-1.942150</td>\n",
       "      <td>1.518630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.691200</td>\n",
       "      <td>-0.127675</td>\n",
       "      <td>0.142289</td>\n",
       "      <td>-0.433567</td>\n",
       "      <td>0.628837</td>\n",
       "      <td>0.344937</td>\n",
       "      <td>0.642042</td>\n",
       "      <td>-0.128452</td>\n",
       "      <td>0.673255</td>\n",
       "      <td>1.655773</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.925059</td>\n",
       "      <td>-0.382387</td>\n",
       "      <td>0.240937</td>\n",
       "      <td>1.259737</td>\n",
       "      <td>0.313092</td>\n",
       "      <td>0.479246</td>\n",
       "      <td>1.332200</td>\n",
       "      <td>-0.735397</td>\n",
       "      <td>0.978559</td>\n",
       "      <td>-0.822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.934101</td>\n",
       "      <td>-0.404897</td>\n",
       "      <td>-0.349166</td>\n",
       "      <td>-1.665280</td>\n",
       "      <td>-0.525227</td>\n",
       "      <td>0.066715</td>\n",
       "      <td>0.355040</td>\n",
       "      <td>-1.233562</td>\n",
       "      <td>-0.608175</td>\n",
       "      <td>-0.383270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432890</td>\n",
       "      <td>0.674286</td>\n",
       "      <td>-0.064258</td>\n",
       "      <td>-0.944889</td>\n",
       "      <td>-1.078897</td>\n",
       "      <td>-0.801034</td>\n",
       "      <td>0.269001</td>\n",
       "      <td>-1.709661</td>\n",
       "      <td>0.382265</td>\n",
       "      <td>0.537923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.741762</td>\n",
       "      <td>0.847339</td>\n",
       "      <td>-1.275101</td>\n",
       "      <td>-1.184877</td>\n",
       "      <td>-0.369747</td>\n",
       "      <td>-0.378966</td>\n",
       "      <td>-1.348889</td>\n",
       "      <td>-0.776579</td>\n",
       "      <td>-0.312644</td>\n",
       "      <td>-0.306435</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.693454</td>\n",
       "      <td>0.532657</td>\n",
       "      <td>-1.613731</td>\n",
       "      <td>1.625088</td>\n",
       "      <td>-0.476602</td>\n",
       "      <td>-1.179684</td>\n",
       "      <td>0.232037</td>\n",
       "      <td>1.838190</td>\n",
       "      <td>-0.704720</td>\n",
       "      <td>0.876326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.173525</td>\n",
       "      <td>-0.136488</td>\n",
       "      <td>0.338063</td>\n",
       "      <td>-0.162307</td>\n",
       "      <td>-1.303650</td>\n",
       "      <td>0.847927</td>\n",
       "      <td>-0.471892</td>\n",
       "      <td>-0.403960</td>\n",
       "      <td>-0.808899</td>\n",
       "      <td>-1.956698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488654</td>\n",
       "      <td>0.399122</td>\n",
       "      <td>1.839348</td>\n",
       "      <td>0.605970</td>\n",
       "      <td>-1.287595</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>-0.132577</td>\n",
       "      <td>0.957579</td>\n",
       "      <td>1.284221</td>\n",
       "      <td>-0.678374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.834499</td>\n",
       "      <td>1.013493</td>\n",
       "      <td>-0.531999</td>\n",
       "      <td>-0.386696</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>-1.328067</td>\n",
       "      <td>-0.023228</td>\n",
       "      <td>1.519471</td>\n",
       "      <td>1.216906</td>\n",
       "      <td>0.418004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.657509</td>\n",
       "      <td>-0.195108</td>\n",
       "      <td>1.011616</td>\n",
       "      <td>0.272462</td>\n",
       "      <td>1.383491</td>\n",
       "      <td>0.963489</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>-0.131865</td>\n",
       "      <td>-0.116000</td>\n",
       "      <td>0.272825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.200180</td>\n",
       "      <td>0.403002</td>\n",
       "      <td>1.740947</td>\n",
       "      <td>0.958236</td>\n",
       "      <td>2.263537</td>\n",
       "      <td>-0.329996</td>\n",
       "      <td>1.752433</td>\n",
       "      <td>0.666444</td>\n",
       "      <td>0.230499</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233187</td>\n",
       "      <td>1.835561</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>2.097841</td>\n",
       "      <td>0.168282</td>\n",
       "      <td>1.873597</td>\n",
       "      <td>1.529014</td>\n",
       "      <td>0.207111</td>\n",
       "      <td>-0.017888</td>\n",
       "      <td>0.961969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.339229</td>\n",
       "      <td>-0.255037</td>\n",
       "      <td>-1.012482</td>\n",
       "      <td>0.288174</td>\n",
       "      <td>0.093534</td>\n",
       "      <td>-0.091856</td>\n",
       "      <td>0.275040</td>\n",
       "      <td>-1.487241</td>\n",
       "      <td>-1.667573</td>\n",
       "      <td>0.705538</td>\n",
       "      <td>...</td>\n",
       "      <td>1.963178</td>\n",
       "      <td>-0.310566</td>\n",
       "      <td>0.190215</td>\n",
       "      <td>0.827838</td>\n",
       "      <td>-0.548445</td>\n",
       "      <td>0.447461</td>\n",
       "      <td>0.552537</td>\n",
       "      <td>-1.183448</td>\n",
       "      <td>1.029311</td>\n",
       "      <td>-0.780909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.539066</td>\n",
       "      <td>2.791971</td>\n",
       "      <td>1.223733</td>\n",
       "      <td>0.068952</td>\n",
       "      <td>0.602549</td>\n",
       "      <td>-0.787211</td>\n",
       "      <td>1.932821</td>\n",
       "      <td>-0.277332</td>\n",
       "      <td>0.536558</td>\n",
       "      <td>-0.295387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907592</td>\n",
       "      <td>-0.046958</td>\n",
       "      <td>-1.861760</td>\n",
       "      <td>-0.448502</td>\n",
       "      <td>-1.497480</td>\n",
       "      <td>1.033743</td>\n",
       "      <td>-0.461447</td>\n",
       "      <td>0.722109</td>\n",
       "      <td>0.194513</td>\n",
       "      <td>1.135791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.092466</td>\n",
       "      <td>-0.082255</td>\n",
       "      <td>-0.608369</td>\n",
       "      <td>0.977237</td>\n",
       "      <td>0.752587</td>\n",
       "      <td>0.644729</td>\n",
       "      <td>0.296882</td>\n",
       "      <td>-0.536038</td>\n",
       "      <td>1.676288</td>\n",
       "      <td>-0.740078</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.514136</td>\n",
       "      <td>0.603808</td>\n",
       "      <td>-0.454106</td>\n",
       "      <td>-1.969990</td>\n",
       "      <td>1.037509</td>\n",
       "      <td>-0.122944</td>\n",
       "      <td>-0.021804</td>\n",
       "      <td>-0.609123</td>\n",
       "      <td>-0.207297</td>\n",
       "      <td>-1.361811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.000259</td>\n",
       "      <td>-0.304001</td>\n",
       "      <td>1.647555</td>\n",
       "      <td>-0.544829</td>\n",
       "      <td>1.947001</td>\n",
       "      <td>-0.059070</td>\n",
       "      <td>-0.253595</td>\n",
       "      <td>0.872146</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>0.471587</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.620181</td>\n",
       "      <td>-0.918714</td>\n",
       "      <td>-0.824199</td>\n",
       "      <td>1.233520</td>\n",
       "      <td>0.023018</td>\n",
       "      <td>0.571407</td>\n",
       "      <td>-2.039363</td>\n",
       "      <td>-0.576561</td>\n",
       "      <td>0.079145</td>\n",
       "      <td>-1.197674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.968639</td>\n",
       "      <td>0.648398</td>\n",
       "      <td>1.405812</td>\n",
       "      <td>-0.788259</td>\n",
       "      <td>0.948120</td>\n",
       "      <td>-0.778016</td>\n",
       "      <td>-0.650256</td>\n",
       "      <td>1.258830</td>\n",
       "      <td>-0.376926</td>\n",
       "      <td>0.893569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805637</td>\n",
       "      <td>-0.391055</td>\n",
       "      <td>2.140421</td>\n",
       "      <td>0.151129</td>\n",
       "      <td>-0.123127</td>\n",
       "      <td>0.778205</td>\n",
       "      <td>-0.874226</td>\n",
       "      <td>0.281296</td>\n",
       "      <td>-1.210919</td>\n",
       "      <td>-0.091103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.828614</td>\n",
       "      <td>-2.167808</td>\n",
       "      <td>-1.213551</td>\n",
       "      <td>0.493949</td>\n",
       "      <td>-1.364115</td>\n",
       "      <td>-0.146548</td>\n",
       "      <td>0.822049</td>\n",
       "      <td>-0.445526</td>\n",
       "      <td>0.452096</td>\n",
       "      <td>0.118493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617026</td>\n",
       "      <td>0.172731</td>\n",
       "      <td>-1.007513</td>\n",
       "      <td>-0.641697</td>\n",
       "      <td>0.442236</td>\n",
       "      <td>-1.086310</td>\n",
       "      <td>-2.178310</td>\n",
       "      <td>0.168934</td>\n",
       "      <td>-0.092904</td>\n",
       "      <td>0.811843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.356810</td>\n",
       "      <td>-0.667923</td>\n",
       "      <td>-0.414100</td>\n",
       "      <td>2.274703</td>\n",
       "      <td>0.663382</td>\n",
       "      <td>0.612418</td>\n",
       "      <td>0.647999</td>\n",
       "      <td>-0.347457</td>\n",
       "      <td>-0.523604</td>\n",
       "      <td>-0.862127</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.657566</td>\n",
       "      <td>1.477833</td>\n",
       "      <td>-0.913008</td>\n",
       "      <td>1.362358</td>\n",
       "      <td>-1.118084</td>\n",
       "      <td>0.074183</td>\n",
       "      <td>0.263447</td>\n",
       "      <td>-1.826516</td>\n",
       "      <td>-0.351224</td>\n",
       "      <td>-0.299599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.291431</td>\n",
       "      <td>1.497749</td>\n",
       "      <td>0.504189</td>\n",
       "      <td>-1.153509</td>\n",
       "      <td>0.160785</td>\n",
       "      <td>2.210038</td>\n",
       "      <td>-0.485480</td>\n",
       "      <td>-0.229361</td>\n",
       "      <td>-0.247615</td>\n",
       "      <td>1.300336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142119</td>\n",
       "      <td>1.007354</td>\n",
       "      <td>0.752814</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>1.581266</td>\n",
       "      <td>-0.154616</td>\n",
       "      <td>-1.009337</td>\n",
       "      <td>-0.209094</td>\n",
       "      <td>0.696452</td>\n",
       "      <td>1.666319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.788213</td>\n",
       "      <td>-0.702152</td>\n",
       "      <td>2.483354</td>\n",
       "      <td>-1.934866</td>\n",
       "      <td>1.332674</td>\n",
       "      <td>-0.893322</td>\n",
       "      <td>0.144805</td>\n",
       "      <td>1.255251</td>\n",
       "      <td>0.526070</td>\n",
       "      <td>1.105921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337289</td>\n",
       "      <td>0.192494</td>\n",
       "      <td>1.828316</td>\n",
       "      <td>-1.218853</td>\n",
       "      <td>0.130257</td>\n",
       "      <td>2.910900</td>\n",
       "      <td>0.456515</td>\n",
       "      <td>2.040317</td>\n",
       "      <td>0.080433</td>\n",
       "      <td>0.819483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.300657</td>\n",
       "      <td>1.088199</td>\n",
       "      <td>-0.290689</td>\n",
       "      <td>-0.354352</td>\n",
       "      <td>-0.244585</td>\n",
       "      <td>0.460324</td>\n",
       "      <td>1.749072</td>\n",
       "      <td>1.532119</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>-0.858656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088662</td>\n",
       "      <td>0.150469</td>\n",
       "      <td>2.682788</td>\n",
       "      <td>-0.768501</td>\n",
       "      <td>1.122346</td>\n",
       "      <td>0.063651</td>\n",
       "      <td>-0.198887</td>\n",
       "      <td>0.987199</td>\n",
       "      <td>0.485552</td>\n",
       "      <td>2.035827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.059902</td>\n",
       "      <td>-0.380968</td>\n",
       "      <td>0.591846</td>\n",
       "      <td>0.089875</td>\n",
       "      <td>0.573520</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>-0.336222</td>\n",
       "      <td>-0.071371</td>\n",
       "      <td>-1.113551</td>\n",
       "      <td>-1.275093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.422841</td>\n",
       "      <td>-0.987524</td>\n",
       "      <td>1.748075</td>\n",
       "      <td>-1.574052</td>\n",
       "      <td>1.264796</td>\n",
       "      <td>0.259914</td>\n",
       "      <td>0.544842</td>\n",
       "      <td>0.779822</td>\n",
       "      <td>-0.180305</td>\n",
       "      <td>-0.114592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.816026</td>\n",
       "      <td>0.450870</td>\n",
       "      <td>0.604371</td>\n",
       "      <td>-2.262417</td>\n",
       "      <td>-0.459388</td>\n",
       "      <td>-0.025631</td>\n",
       "      <td>-0.400103</td>\n",
       "      <td>2.202473</td>\n",
       "      <td>-1.263990</td>\n",
       "      <td>-0.492838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.488526</td>\n",
       "      <td>1.296895</td>\n",
       "      <td>1.519787</td>\n",
       "      <td>-1.071912</td>\n",
       "      <td>0.918177</td>\n",
       "      <td>-0.080344</td>\n",
       "      <td>-0.179744</td>\n",
       "      <td>-0.692400</td>\n",
       "      <td>0.642983</td>\n",
       "      <td>-1.186788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.142752</td>\n",
       "      <td>0.639761</td>\n",
       "      <td>2.202870</td>\n",
       "      <td>-1.269892</td>\n",
       "      <td>2.476741</td>\n",
       "      <td>-1.545995</td>\n",
       "      <td>-0.735551</td>\n",
       "      <td>0.135511</td>\n",
       "      <td>0.700605</td>\n",
       "      <td>2.155847</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240510</td>\n",
       "      <td>1.075392</td>\n",
       "      <td>1.209142</td>\n",
       "      <td>-0.403709</td>\n",
       "      <td>0.652131</td>\n",
       "      <td>1.998386</td>\n",
       "      <td>-1.655288</td>\n",
       "      <td>-0.375074</td>\n",
       "      <td>-2.050110</td>\n",
       "      <td>0.034512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.329913</td>\n",
       "      <td>0.127361</td>\n",
       "      <td>-0.184765</td>\n",
       "      <td>-1.481288</td>\n",
       "      <td>0.791677</td>\n",
       "      <td>0.856191</td>\n",
       "      <td>-0.292400</td>\n",
       "      <td>0.210559</td>\n",
       "      <td>0.029388</td>\n",
       "      <td>-0.089877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166199</td>\n",
       "      <td>-0.024558</td>\n",
       "      <td>2.028121</td>\n",
       "      <td>0.525236</td>\n",
       "      <td>-0.510688</td>\n",
       "      <td>-0.486759</td>\n",
       "      <td>0.806610</td>\n",
       "      <td>0.833828</td>\n",
       "      <td>-0.642634</td>\n",
       "      <td>1.688117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.357916</td>\n",
       "      <td>-0.107718</td>\n",
       "      <td>-0.663272</td>\n",
       "      <td>0.584295</td>\n",
       "      <td>0.430758</td>\n",
       "      <td>1.301542</td>\n",
       "      <td>-0.552674</td>\n",
       "      <td>-0.789251</td>\n",
       "      <td>0.534989</td>\n",
       "      <td>0.645842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.782632</td>\n",
       "      <td>0.565539</td>\n",
       "      <td>1.427701</td>\n",
       "      <td>-0.146075</td>\n",
       "      <td>-0.774683</td>\n",
       "      <td>-0.177307</td>\n",
       "      <td>0.041243</td>\n",
       "      <td>-0.041427</td>\n",
       "      <td>-0.401074</td>\n",
       "      <td>-0.886501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.103207</td>\n",
       "      <td>0.794941</td>\n",
       "      <td>-0.495627</td>\n",
       "      <td>-0.064381</td>\n",
       "      <td>0.268022</td>\n",
       "      <td>-0.358703</td>\n",
       "      <td>0.172630</td>\n",
       "      <td>0.817371</td>\n",
       "      <td>0.160823</td>\n",
       "      <td>-0.477412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492614</td>\n",
       "      <td>-0.483204</td>\n",
       "      <td>0.679723</td>\n",
       "      <td>-1.162005</td>\n",
       "      <td>1.431226</td>\n",
       "      <td>0.440273</td>\n",
       "      <td>-1.091537</td>\n",
       "      <td>-2.037076</td>\n",
       "      <td>-1.875155</td>\n",
       "      <td>-0.008665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.040958</td>\n",
       "      <td>-0.578571</td>\n",
       "      <td>0.745698</td>\n",
       "      <td>-1.064159</td>\n",
       "      <td>-0.071315</td>\n",
       "      <td>0.047977</td>\n",
       "      <td>0.705784</td>\n",
       "      <td>2.492505</td>\n",
       "      <td>-1.337085</td>\n",
       "      <td>0.250375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359694</td>\n",
       "      <td>1.687578</td>\n",
       "      <td>-0.658343</td>\n",
       "      <td>-0.877079</td>\n",
       "      <td>-1.550752</td>\n",
       "      <td>0.470490</td>\n",
       "      <td>-0.125226</td>\n",
       "      <td>-1.165412</td>\n",
       "      <td>-0.051151</td>\n",
       "      <td>0.409614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.765477</td>\n",
       "      <td>-0.842630</td>\n",
       "      <td>1.138487</td>\n",
       "      <td>0.017519</td>\n",
       "      <td>0.231019</td>\n",
       "      <td>-0.870662</td>\n",
       "      <td>-0.472327</td>\n",
       "      <td>0.402709</td>\n",
       "      <td>-0.834813</td>\n",
       "      <td>-1.623028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255448</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.380609</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>-1.092998</td>\n",
       "      <td>0.963629</td>\n",
       "      <td>-1.303065</td>\n",
       "      <td>-0.991181</td>\n",
       "      <td>1.252048</td>\n",
       "      <td>-1.161991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.719439</td>\n",
       "      <td>-1.015577</td>\n",
       "      <td>-0.028201</td>\n",
       "      <td>-0.928710</td>\n",
       "      <td>-1.382421</td>\n",
       "      <td>1.162265</td>\n",
       "      <td>0.701342</td>\n",
       "      <td>-1.076968</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>-1.826256</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759138</td>\n",
       "      <td>0.253365</td>\n",
       "      <td>-0.359285</td>\n",
       "      <td>0.314776</td>\n",
       "      <td>0.909865</td>\n",
       "      <td>0.862814</td>\n",
       "      <td>-1.369782</td>\n",
       "      <td>0.429608</td>\n",
       "      <td>0.784438</td>\n",
       "      <td>-0.077056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1.191850</td>\n",
       "      <td>0.018312</td>\n",
       "      <td>-1.371763</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>-2.162383</td>\n",
       "      <td>-0.012360</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>-0.047282</td>\n",
       "      <td>0.670949</td>\n",
       "      <td>-0.776838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.494400</td>\n",
       "      <td>-0.018289</td>\n",
       "      <td>1.533713</td>\n",
       "      <td>-1.213655</td>\n",
       "      <td>0.124575</td>\n",
       "      <td>-1.231166</td>\n",
       "      <td>0.225322</td>\n",
       "      <td>1.325321</td>\n",
       "      <td>0.070505</td>\n",
       "      <td>-0.391708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.286493</td>\n",
       "      <td>-0.193927</td>\n",
       "      <td>2.184565</td>\n",
       "      <td>-0.125139</td>\n",
       "      <td>0.844956</td>\n",
       "      <td>0.690096</td>\n",
       "      <td>-1.117412</td>\n",
       "      <td>-0.808346</td>\n",
       "      <td>0.309479</td>\n",
       "      <td>-0.269975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073112</td>\n",
       "      <td>0.737225</td>\n",
       "      <td>1.346217</td>\n",
       "      <td>-1.737192</td>\n",
       "      <td>-1.013179</td>\n",
       "      <td>2.118034</td>\n",
       "      <td>1.640718</td>\n",
       "      <td>1.052812</td>\n",
       "      <td>0.697189</td>\n",
       "      <td>0.625568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>-0.159086</td>\n",
       "      <td>-0.347987</td>\n",
       "      <td>-0.119799</td>\n",
       "      <td>-0.530478</td>\n",
       "      <td>-0.133084</td>\n",
       "      <td>-0.895888</td>\n",
       "      <td>-0.771693</td>\n",
       "      <td>-1.180093</td>\n",
       "      <td>-0.210127</td>\n",
       "      <td>1.381785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281706</td>\n",
       "      <td>-0.674630</td>\n",
       "      <td>1.627711</td>\n",
       "      <td>-0.476788</td>\n",
       "      <td>0.352119</td>\n",
       "      <td>0.394137</td>\n",
       "      <td>0.052393</td>\n",
       "      <td>1.709851</td>\n",
       "      <td>-0.494264</td>\n",
       "      <td>0.144678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>-0.852743</td>\n",
       "      <td>-2.459622</td>\n",
       "      <td>-1.542767</td>\n",
       "      <td>-0.465323</td>\n",
       "      <td>-1.656277</td>\n",
       "      <td>0.497990</td>\n",
       "      <td>0.157076</td>\n",
       "      <td>1.568725</td>\n",
       "      <td>-0.833717</td>\n",
       "      <td>0.607353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469496</td>\n",
       "      <td>0.271537</td>\n",
       "      <td>0.638085</td>\n",
       "      <td>-1.358878</td>\n",
       "      <td>0.159311</td>\n",
       "      <td>-0.281003</td>\n",
       "      <td>-0.408173</td>\n",
       "      <td>-0.195773</td>\n",
       "      <td>1.925356</td>\n",
       "      <td>-0.257296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>-0.680498</td>\n",
       "      <td>0.470634</td>\n",
       "      <td>2.389021</td>\n",
       "      <td>0.738402</td>\n",
       "      <td>1.852728</td>\n",
       "      <td>1.589603</td>\n",
       "      <td>-0.515899</td>\n",
       "      <td>0.592363</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>1.374765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215889</td>\n",
       "      <td>0.376747</td>\n",
       "      <td>0.936373</td>\n",
       "      <td>-1.179268</td>\n",
       "      <td>-0.661063</td>\n",
       "      <td>2.244349</td>\n",
       "      <td>-0.303157</td>\n",
       "      <td>0.854584</td>\n",
       "      <td>-0.841527</td>\n",
       "      <td>-0.394065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-0.400637</td>\n",
       "      <td>-0.336164</td>\n",
       "      <td>1.689476</td>\n",
       "      <td>-0.904433</td>\n",
       "      <td>1.241069</td>\n",
       "      <td>0.532052</td>\n",
       "      <td>2.395773</td>\n",
       "      <td>-0.022819</td>\n",
       "      <td>-0.848305</td>\n",
       "      <td>-0.702388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.105312</td>\n",
       "      <td>-0.185239</td>\n",
       "      <td>-0.158070</td>\n",
       "      <td>1.089971</td>\n",
       "      <td>-0.857535</td>\n",
       "      <td>2.080588</td>\n",
       "      <td>-0.285347</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>1.640151</td>\n",
       "      <td>0.809219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1.692350</td>\n",
       "      <td>1.014767</td>\n",
       "      <td>-0.770564</td>\n",
       "      <td>0.403176</td>\n",
       "      <td>0.153323</td>\n",
       "      <td>-1.133295</td>\n",
       "      <td>0.466836</td>\n",
       "      <td>0.328154</td>\n",
       "      <td>-0.341631</td>\n",
       "      <td>0.831014</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.536445</td>\n",
       "      <td>-2.564477</td>\n",
       "      <td>-0.234192</td>\n",
       "      <td>0.623118</td>\n",
       "      <td>1.754201</td>\n",
       "      <td>-0.837495</td>\n",
       "      <td>1.879102</td>\n",
       "      <td>1.388051</td>\n",
       "      <td>-0.760446</td>\n",
       "      <td>0.528030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.878195</td>\n",
       "      <td>0.202421</td>\n",
       "      <td>-0.313637</td>\n",
       "      <td>-1.581041</td>\n",
       "      <td>-1.750493</td>\n",
       "      <td>-0.003461</td>\n",
       "      <td>-0.439223</td>\n",
       "      <td>-1.959668</td>\n",
       "      <td>-1.077590</td>\n",
       "      <td>-1.954408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077934</td>\n",
       "      <td>-0.226854</td>\n",
       "      <td>-0.326672</td>\n",
       "      <td>-0.539372</td>\n",
       "      <td>0.238348</td>\n",
       "      <td>0.314608</td>\n",
       "      <td>-2.203816</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.542399</td>\n",
       "      <td>1.389343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.418542</td>\n",
       "      <td>1.570315</td>\n",
       "      <td>0.241854</td>\n",
       "      <td>0.063807</td>\n",
       "      <td>0.201679</td>\n",
       "      <td>0.328600</td>\n",
       "      <td>0.629714</td>\n",
       "      <td>0.279478</td>\n",
       "      <td>-0.246831</td>\n",
       "      <td>-0.873831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060307</td>\n",
       "      <td>-1.899385</td>\n",
       "      <td>-0.254404</td>\n",
       "      <td>-0.433326</td>\n",
       "      <td>-1.633942</td>\n",
       "      <td>0.777557</td>\n",
       "      <td>0.488686</td>\n",
       "      <td>-0.117312</td>\n",
       "      <td>-1.234208</td>\n",
       "      <td>0.615680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-0.041802</td>\n",
       "      <td>-0.006478</td>\n",
       "      <td>-0.705482</td>\n",
       "      <td>-0.455485</td>\n",
       "      <td>-1.046096</td>\n",
       "      <td>-0.143571</td>\n",
       "      <td>0.506102</td>\n",
       "      <td>-0.964631</td>\n",
       "      <td>-1.194054</td>\n",
       "      <td>-1.362640</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.725553</td>\n",
       "      <td>-0.875762</td>\n",
       "      <td>0.355848</td>\n",
       "      <td>0.393084</td>\n",
       "      <td>-0.892655</td>\n",
       "      <td>-0.199977</td>\n",
       "      <td>-1.698224</td>\n",
       "      <td>-0.530143</td>\n",
       "      <td>-0.100622</td>\n",
       "      <td>0.786532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>-1.251078</td>\n",
       "      <td>-0.217958</td>\n",
       "      <td>-1.834318</td>\n",
       "      <td>1.651784</td>\n",
       "      <td>-0.791358</td>\n",
       "      <td>-0.987183</td>\n",
       "      <td>-0.133926</td>\n",
       "      <td>0.260590</td>\n",
       "      <td>-1.758692</td>\n",
       "      <td>-0.044246</td>\n",
       "      <td>...</td>\n",
       "      <td>1.374209</td>\n",
       "      <td>1.215865</td>\n",
       "      <td>0.719087</td>\n",
       "      <td>0.336805</td>\n",
       "      <td>0.639550</td>\n",
       "      <td>-0.528596</td>\n",
       "      <td>0.813380</td>\n",
       "      <td>0.903790</td>\n",
       "      <td>0.859407</td>\n",
       "      <td>-0.667846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.122223</td>\n",
       "      <td>0.150395</td>\n",
       "      <td>0.258357</td>\n",
       "      <td>-0.148301</td>\n",
       "      <td>-0.278262</td>\n",
       "      <td>-0.768340</td>\n",
       "      <td>0.199434</td>\n",
       "      <td>1.836281</td>\n",
       "      <td>-1.191013</td>\n",
       "      <td>0.347430</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313130</td>\n",
       "      <td>0.859501</td>\n",
       "      <td>-1.830169</td>\n",
       "      <td>1.510086</td>\n",
       "      <td>1.006010</td>\n",
       "      <td>1.450007</td>\n",
       "      <td>-0.428709</td>\n",
       "      <td>-0.353205</td>\n",
       "      <td>-0.141457</td>\n",
       "      <td>-0.166389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.256132</td>\n",
       "      <td>-0.783504</td>\n",
       "      <td>1.300482</td>\n",
       "      <td>-1.102415</td>\n",
       "      <td>1.446241</td>\n",
       "      <td>0.648516</td>\n",
       "      <td>-1.120924</td>\n",
       "      <td>-0.636984</td>\n",
       "      <td>-0.875119</td>\n",
       "      <td>-1.161587</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.355296</td>\n",
       "      <td>0.047962</td>\n",
       "      <td>-0.096390</td>\n",
       "      <td>-0.089237</td>\n",
       "      <td>0.182282</td>\n",
       "      <td>0.834032</td>\n",
       "      <td>-0.546210</td>\n",
       "      <td>0.043812</td>\n",
       "      <td>1.795072</td>\n",
       "      <td>1.037416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>-0.377088</td>\n",
       "      <td>-0.556460</td>\n",
       "      <td>0.663348</td>\n",
       "      <td>-1.645365</td>\n",
       "      <td>1.141562</td>\n",
       "      <td>0.505522</td>\n",
       "      <td>-1.275469</td>\n",
       "      <td>0.274370</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.901013</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.175760</td>\n",
       "      <td>-0.470270</td>\n",
       "      <td>0.725103</td>\n",
       "      <td>-1.446059</td>\n",
       "      <td>0.166252</td>\n",
       "      <td>-1.213046</td>\n",
       "      <td>-0.686100</td>\n",
       "      <td>-1.946530</td>\n",
       "      <td>1.051437</td>\n",
       "      <td>0.597908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.014030</td>\n",
       "      <td>-0.547886</td>\n",
       "      <td>-0.496124</td>\n",
       "      <td>1.637255</td>\n",
       "      <td>-1.277353</td>\n",
       "      <td>1.113104</td>\n",
       "      <td>0.326493</td>\n",
       "      <td>-0.505417</td>\n",
       "      <td>-1.275018</td>\n",
       "      <td>0.588087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.508914</td>\n",
       "      <td>-1.878868</td>\n",
       "      <td>-0.357748</td>\n",
       "      <td>0.176305</td>\n",
       "      <td>0.435865</td>\n",
       "      <td>0.223716</td>\n",
       "      <td>1.234651</td>\n",
       "      <td>-0.518015</td>\n",
       "      <td>0.592277</td>\n",
       "      <td>0.124244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-1.872243</td>\n",
       "      <td>0.641295</td>\n",
       "      <td>0.389615</td>\n",
       "      <td>2.163605</td>\n",
       "      <td>1.228714</td>\n",
       "      <td>-0.196141</td>\n",
       "      <td>-0.916490</td>\n",
       "      <td>-0.334945</td>\n",
       "      <td>-0.978257</td>\n",
       "      <td>1.414944</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.482976</td>\n",
       "      <td>-0.443699</td>\n",
       "      <td>-2.747835</td>\n",
       "      <td>-0.351952</td>\n",
       "      <td>0.731784</td>\n",
       "      <td>-0.639598</td>\n",
       "      <td>-1.115431</td>\n",
       "      <td>-0.403971</td>\n",
       "      <td>1.116513</td>\n",
       "      <td>1.140286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.295109</td>\n",
       "      <td>1.430721</td>\n",
       "      <td>-0.893506</td>\n",
       "      <td>-3.747447</td>\n",
       "      <td>-0.666322</td>\n",
       "      <td>-0.860429</td>\n",
       "      <td>0.474896</td>\n",
       "      <td>2.270370</td>\n",
       "      <td>0.191129</td>\n",
       "      <td>-0.401860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.368457</td>\n",
       "      <td>1.730497</td>\n",
       "      <td>0.578539</td>\n",
       "      <td>1.437438</td>\n",
       "      <td>0.186362</td>\n",
       "      <td>-0.052468</td>\n",
       "      <td>0.012282</td>\n",
       "      <td>0.516301</td>\n",
       "      <td>-0.725883</td>\n",
       "      <td>0.769331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-0.232370</td>\n",
       "      <td>-0.103312</td>\n",
       "      <td>0.655483</td>\n",
       "      <td>0.383281</td>\n",
       "      <td>-0.103954</td>\n",
       "      <td>-1.539060</td>\n",
       "      <td>-0.259278</td>\n",
       "      <td>0.942587</td>\n",
       "      <td>-0.626337</td>\n",
       "      <td>-1.096907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195443</td>\n",
       "      <td>-0.891175</td>\n",
       "      <td>0.058723</td>\n",
       "      <td>-0.391545</td>\n",
       "      <td>0.227356</td>\n",
       "      <td>-1.679019</td>\n",
       "      <td>0.449165</td>\n",
       "      <td>-0.178523</td>\n",
       "      <td>0.283603</td>\n",
       "      <td>-1.019215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>-0.104961</td>\n",
       "      <td>0.455295</td>\n",
       "      <td>0.866376</td>\n",
       "      <td>1.129370</td>\n",
       "      <td>-0.292138</td>\n",
       "      <td>0.387415</td>\n",
       "      <td>-0.954537</td>\n",
       "      <td>-1.158009</td>\n",
       "      <td>-0.570324</td>\n",
       "      <td>-1.092600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611624</td>\n",
       "      <td>0.487866</td>\n",
       "      <td>0.172767</td>\n",
       "      <td>-0.669769</td>\n",
       "      <td>1.601192</td>\n",
       "      <td>0.353912</td>\n",
       "      <td>2.325475</td>\n",
       "      <td>0.253087</td>\n",
       "      <td>0.276432</td>\n",
       "      <td>-1.004216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.457030</td>\n",
       "      <td>-0.911178</td>\n",
       "      <td>1.617018</td>\n",
       "      <td>-0.646556</td>\n",
       "      <td>-1.333241</td>\n",
       "      <td>-0.848727</td>\n",
       "      <td>0.666899</td>\n",
       "      <td>0.368037</td>\n",
       "      <td>-1.491658</td>\n",
       "      <td>0.177186</td>\n",
       "      <td>...</td>\n",
       "      <td>1.377023</td>\n",
       "      <td>1.115438</td>\n",
       "      <td>-0.146635</td>\n",
       "      <td>1.869824</td>\n",
       "      <td>-1.169580</td>\n",
       "      <td>0.523679</td>\n",
       "      <td>-2.392640</td>\n",
       "      <td>-0.728643</td>\n",
       "      <td>1.001824</td>\n",
       "      <td>-2.619280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>-0.551970</td>\n",
       "      <td>0.516803</td>\n",
       "      <td>1.423248</td>\n",
       "      <td>-1.149419</td>\n",
       "      <td>0.407676</td>\n",
       "      <td>-0.650266</td>\n",
       "      <td>1.308833</td>\n",
       "      <td>3.650623</td>\n",
       "      <td>1.682264</td>\n",
       "      <td>0.936215</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843937</td>\n",
       "      <td>-0.339714</td>\n",
       "      <td>-0.409672</td>\n",
       "      <td>0.024755</td>\n",
       "      <td>-0.514596</td>\n",
       "      <td>-0.513056</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>-0.813216</td>\n",
       "      <td>-0.756909</td>\n",
       "      <td>-0.013165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1.482465</td>\n",
       "      <td>-0.126938</td>\n",
       "      <td>-1.399061</td>\n",
       "      <td>-0.145390</td>\n",
       "      <td>-2.125978</td>\n",
       "      <td>1.431212</td>\n",
       "      <td>1.091367</td>\n",
       "      <td>0.049615</td>\n",
       "      <td>-0.844883</td>\n",
       "      <td>1.662772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-1.239547</td>\n",
       "      <td>0.193902</td>\n",
       "      <td>0.806774</td>\n",
       "      <td>-1.535845</td>\n",
       "      <td>-1.671239</td>\n",
       "      <td>-0.698848</td>\n",
       "      <td>-0.988954</td>\n",
       "      <td>2.477496</td>\n",
       "      <td>1.997063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.210460</td>\n",
       "      <td>0.386752</td>\n",
       "      <td>-0.262848</td>\n",
       "      <td>2.057435</td>\n",
       "      <td>0.744295</td>\n",
       "      <td>-0.899921</td>\n",
       "      <td>-0.890254</td>\n",
       "      <td>0.047947</td>\n",
       "      <td>-1.448027</td>\n",
       "      <td>2.168663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310410</td>\n",
       "      <td>-0.523617</td>\n",
       "      <td>0.295704</td>\n",
       "      <td>-0.780874</td>\n",
       "      <td>1.330365</td>\n",
       "      <td>-0.445954</td>\n",
       "      <td>-1.375572</td>\n",
       "      <td>0.852129</td>\n",
       "      <td>0.409654</td>\n",
       "      <td>1.137497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.485426</td>\n",
       "      <td>-1.035249</td>\n",
       "      <td>-0.003374</td>\n",
       "      <td>-0.843034</td>\n",
       "      <td>-0.296256</td>\n",
       "      <td>-1.545167</td>\n",
       "      <td>0.818210</td>\n",
       "      <td>1.257188</td>\n",
       "      <td>0.446759</td>\n",
       "      <td>-0.717149</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628739</td>\n",
       "      <td>-0.176509</td>\n",
       "      <td>-2.643964</td>\n",
       "      <td>-0.021249</td>\n",
       "      <td>-1.280983</td>\n",
       "      <td>-0.638719</td>\n",
       "      <td>-1.077257</td>\n",
       "      <td>0.642512</td>\n",
       "      <td>-1.342502</td>\n",
       "      <td>0.522688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.268017</td>\n",
       "      <td>-0.554049</td>\n",
       "      <td>-1.509600</td>\n",
       "      <td>0.462102</td>\n",
       "      <td>-0.298409</td>\n",
       "      <td>0.246194</td>\n",
       "      <td>-1.607855</td>\n",
       "      <td>-1.118633</td>\n",
       "      <td>-0.037854</td>\n",
       "      <td>1.027436</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.442001</td>\n",
       "      <td>0.192543</td>\n",
       "      <td>-2.150644</td>\n",
       "      <td>-0.347355</td>\n",
       "      <td>0.045971</td>\n",
       "      <td>-0.294138</td>\n",
       "      <td>-0.482686</td>\n",
       "      <td>-0.283465</td>\n",
       "      <td>0.983899</td>\n",
       "      <td>1.742714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.251578</td>\n",
       "      <td>0.937515</td>\n",
       "      <td>-1.197979</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0.928663</td>\n",
       "      <td>0.537280</td>\n",
       "      <td>0.247568</td>\n",
       "      <td>-1.462313</td>\n",
       "      <td>-0.388814</td>\n",
       "      <td>-2.353651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.739201</td>\n",
       "      <td>1.235095</td>\n",
       "      <td>0.275328</td>\n",
       "      <td>0.582903</td>\n",
       "      <td>-0.549433</td>\n",
       "      <td>0.460677</td>\n",
       "      <td>1.218235</td>\n",
       "      <td>0.102455</td>\n",
       "      <td>3.003444</td>\n",
       "      <td>-0.034359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.624585</td>\n",
       "      <td>-1.058952</td>\n",
       "      <td>0.949132</td>\n",
       "      <td>0.268703</td>\n",
       "      <td>0.661003</td>\n",
       "      <td>-1.665738</td>\n",
       "      <td>0.398169</td>\n",
       "      <td>0.557816</td>\n",
       "      <td>0.635095</td>\n",
       "      <td>-0.232625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609539</td>\n",
       "      <td>0.208579</td>\n",
       "      <td>-2.033640</td>\n",
       "      <td>-0.107492</td>\n",
       "      <td>0.899276</td>\n",
       "      <td>-0.422913</td>\n",
       "      <td>0.397747</td>\n",
       "      <td>-0.080801</td>\n",
       "      <td>-1.705400</td>\n",
       "      <td>-0.478646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.267662</td>\n",
       "      <td>0.180192</td>\n",
       "      <td>0.715367</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>-0.902320</td>\n",
       "      <td>-1.779228</td>\n",
       "      <td>-0.012054</td>\n",
       "      <td>-0.131147</td>\n",
       "      <td>0.203176</td>\n",
       "      <td>0.578609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475324</td>\n",
       "      <td>-0.266354</td>\n",
       "      <td>-0.566444</td>\n",
       "      <td>0.849093</td>\n",
       "      <td>0.746858</td>\n",
       "      <td>0.207070</td>\n",
       "      <td>-1.009005</td>\n",
       "      <td>0.331707</td>\n",
       "      <td>-1.751323</td>\n",
       "      <td>-0.539687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.192560</td>\n",
       "      <td>0.783374</td>\n",
       "      <td>1.705579</td>\n",
       "      <td>0.341813</td>\n",
       "      <td>-0.835031</td>\n",
       "      <td>0.406812</td>\n",
       "      <td>0.049528</td>\n",
       "      <td>2.552551</td>\n",
       "      <td>-0.521071</td>\n",
       "      <td>1.339807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110808</td>\n",
       "      <td>0.810555</td>\n",
       "      <td>-0.908970</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>0.148263</td>\n",
       "      <td>0.501929</td>\n",
       "      <td>-0.001994</td>\n",
       "      <td>-1.664151</td>\n",
       "      <td>2.511700</td>\n",
       "      <td>-0.011796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.042665</td>\n",
       "      <td>0.402802</td>\n",
       "      <td>-0.608509</td>\n",
       "      <td>1.084484</td>\n",
       "      <td>0.103275</td>\n",
       "      <td>0.269790</td>\n",
       "      <td>-0.859766</td>\n",
       "      <td>-0.982158</td>\n",
       "      <td>-0.720435</td>\n",
       "      <td>-3.568840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155850</td>\n",
       "      <td>0.538137</td>\n",
       "      <td>-0.769790</td>\n",
       "      <td>-0.358702</td>\n",
       "      <td>-0.312090</td>\n",
       "      <td>-0.763049</td>\n",
       "      <td>0.652486</td>\n",
       "      <td>0.616117</td>\n",
       "      <td>-0.090219</td>\n",
       "      <td>-1.021522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "index                                                                         \n",
       "0      1.491390  0.164441  1.231538  1.242870  1.557584  0.045490  0.130215   \n",
       "1     -0.274878  0.278034 -1.310784  0.680072 -0.550258  0.635943 -0.447771   \n",
       "2     -0.224313 -0.570958 -0.271176 -0.132801 -1.004479  0.931530 -1.450683   \n",
       "3      0.585318 -0.853202 -0.272304 -0.549254 -2.982352 -0.169744 -0.043042   \n",
       "4     -1.415519  1.418729  0.602669 -0.799339  0.293878 -0.179589 -0.713989   \n",
       "5     -0.691200 -0.127675  0.142289 -0.433567  0.628837  0.344937  0.642042   \n",
       "6      0.934101 -0.404897 -0.349166 -1.665280 -0.525227  0.066715  0.355040   \n",
       "7      0.741762  0.847339 -1.275101 -1.184877 -0.369747 -0.378966 -1.348889   \n",
       "8     -1.173525 -0.136488  0.338063 -0.162307 -1.303650  0.847927 -0.471892   \n",
       "9      0.834499  1.013493 -0.531999 -0.386696  0.015236 -1.328067 -0.023228   \n",
       "10    -0.200180  0.403002  1.740947  0.958236  2.263537 -0.329996  1.752433   \n",
       "11     0.339229 -0.255037 -1.012482  0.288174  0.093534 -0.091856  0.275040   \n",
       "12    -1.539066  2.791971  1.223733  0.068952  0.602549 -0.787211  1.932821   \n",
       "13     0.092466 -0.082255 -0.608369  0.977237  0.752587  0.644729  0.296882   \n",
       "14    -1.000259 -0.304001  1.647555 -0.544829  1.947001 -0.059070 -0.253595   \n",
       "15     0.968639  0.648398  1.405812 -0.788259  0.948120 -0.778016 -0.650256   \n",
       "16    -0.828614 -2.167808 -1.213551  0.493949 -1.364115 -0.146548  0.822049   \n",
       "17     1.356810 -0.667923 -0.414100  2.274703  0.663382  0.612418  0.647999   \n",
       "18     0.291431  1.497749  0.504189 -1.153509  0.160785  2.210038 -0.485480   \n",
       "19    -0.788213 -0.702152  2.483354 -1.934866  1.332674 -0.893322  0.144805   \n",
       "20    -0.300657  1.088199 -0.290689 -0.354352 -0.244585  0.460324  1.749072   \n",
       "21    -2.059902 -0.380968  0.591846  0.089875  0.573520  0.822430 -0.336222   \n",
       "22    -0.816026  0.450870  0.604371 -2.262417 -0.459388 -0.025631 -0.400103   \n",
       "23     0.142752  0.639761  2.202870 -1.269892  2.476741 -1.545995 -0.735551   \n",
       "24     0.329913  0.127361 -0.184765 -1.481288  0.791677  0.856191 -0.292400   \n",
       "25     1.357916 -0.107718 -0.663272  0.584295  0.430758  1.301542 -0.552674   \n",
       "26    -0.103207  0.794941 -0.495627 -0.064381  0.268022 -0.358703  0.172630   \n",
       "27     0.040958 -0.578571  0.745698 -1.064159 -0.071315  0.047977  0.705784   \n",
       "28    -1.765477 -0.842630  1.138487  0.017519  0.231019 -0.870662 -0.472327   \n",
       "29     0.719439 -1.015577 -0.028201 -0.928710 -1.382421  1.162265  0.701342   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "470    1.191850  0.018312 -1.371763  0.106000 -2.162383 -0.012360  0.945196   \n",
       "471    0.286493 -0.193927  2.184565 -0.125139  0.844956  0.690096 -1.117412   \n",
       "472   -0.159086 -0.347987 -0.119799 -0.530478 -0.133084 -0.895888 -0.771693   \n",
       "473   -0.852743 -2.459622 -1.542767 -0.465323 -1.656277  0.497990  0.157076   \n",
       "474   -0.680498  0.470634  2.389021  0.738402  1.852728  1.589603 -0.515899   \n",
       "475   -0.400637 -0.336164  1.689476 -0.904433  1.241069  0.532052  2.395773   \n",
       "476    1.692350  1.014767 -0.770564  0.403176  0.153323 -1.133295  0.466836   \n",
       "477    0.878195  0.202421 -0.313637 -1.581041 -1.750493 -0.003461 -0.439223   \n",
       "478    0.418542  1.570315  0.241854  0.063807  0.201679  0.328600  0.629714   \n",
       "479   -0.041802 -0.006478 -0.705482 -0.455485 -1.046096 -0.143571  0.506102   \n",
       "480   -1.251078 -0.217958 -1.834318  1.651784 -0.791358 -0.987183 -0.133926   \n",
       "481    0.122223  0.150395  0.258357 -0.148301 -0.278262 -0.768340  0.199434   \n",
       "482    0.256132 -0.783504  1.300482 -1.102415  1.446241  0.648516 -1.120924   \n",
       "483   -0.377088 -0.556460  0.663348 -1.645365  1.141562  0.505522 -1.275469   \n",
       "484    0.014030 -0.547886 -0.496124  1.637255 -1.277353  1.113104  0.326493   \n",
       "485   -1.872243  0.641295  0.389615  2.163605  1.228714 -0.196141 -0.916490   \n",
       "486    0.295109  1.430721 -0.893506 -3.747447 -0.666322 -0.860429  0.474896   \n",
       "487   -0.232370 -0.103312  0.655483  0.383281 -0.103954 -1.539060 -0.259278   \n",
       "488   -0.104961  0.455295  0.866376  1.129370 -0.292138  0.387415 -0.954537   \n",
       "489    0.457030 -0.911178  1.617018 -0.646556 -1.333241 -0.848727  0.666899   \n",
       "490   -0.551970  0.516803  1.423248 -1.149419  0.407676 -0.650266  1.308833   \n",
       "491    1.482465 -0.126938 -1.399061 -0.145390 -2.125978  1.431212  1.091367   \n",
       "492    0.210460  0.386752 -0.262848  2.057435  0.744295 -0.899921 -0.890254   \n",
       "493    0.485426 -1.035249 -0.003374 -0.843034 -0.296256 -1.545167  0.818210   \n",
       "494    0.268017 -0.554049 -1.509600  0.462102 -0.298409  0.246194 -1.607855   \n",
       "495    0.251578  0.937515 -1.197979  0.457682  0.928663  0.537280  0.247568   \n",
       "496    0.624585 -1.058952  0.949132  0.268703  0.661003 -1.665738  0.398169   \n",
       "497    0.267662  0.180192  0.715367  0.354242 -0.902320 -1.779228 -0.012054   \n",
       "498    0.192560  0.783374  1.705579  0.341813 -0.835031  0.406812  0.049528   \n",
       "499    0.042665  0.402802 -0.608509  1.084484  0.103275  0.269790 -0.859766   \n",
       "\n",
       "              7         8         9    ...          190       191       192  \\\n",
       "index                                  ...                                    \n",
       "0     -0.434351  1.608691 -0.275786    ...     1.495644  0.386186 -1.085902   \n",
       "1      1.612193  0.523218 -0.817668    ...     0.029643  0.003645 -0.682538   \n",
       "2     -1.708992 -0.448392 -2.122299    ...     0.058687 -2.443076  1.984582   \n",
       "3     -0.415619 -0.383416  0.874080    ...    -2.187086 -0.379730  0.287214   \n",
       "4     -0.148405  0.023052  0.426702    ...    -1.730989 -0.470786 -0.893196   \n",
       "5     -0.128452  0.673255  1.655773    ...    -1.925059 -0.382387  0.240937   \n",
       "6     -1.233562 -0.608175 -0.383270    ...     0.432890  0.674286 -0.064258   \n",
       "7     -0.776579 -0.312644 -0.306435    ...    -1.693454  0.532657 -1.613731   \n",
       "8     -0.403960 -0.808899 -1.956698    ...     0.488654  0.399122  1.839348   \n",
       "9      1.519471  1.216906  0.418004    ...    -1.657509 -0.195108  1.011616   \n",
       "10     0.666444  0.230499  0.133328    ...    -0.233187  1.835561  0.115240   \n",
       "11    -1.487241 -1.667573  0.705538    ...     1.963178 -0.310566  0.190215   \n",
       "12    -0.277332  0.536558 -0.295387    ...    -0.907592 -0.046958 -1.861760   \n",
       "13    -0.536038  1.676288 -0.740078    ...    -1.514136  0.603808 -0.454106   \n",
       "14     0.872146  0.130762  0.471587    ...    -1.620181 -0.918714 -0.824199   \n",
       "15     1.258830 -0.376926  0.893569    ...     0.805637 -0.391055  2.140421   \n",
       "16    -0.445526  0.452096  0.118493    ...     0.617026  0.172731 -1.007513   \n",
       "17    -0.347457 -0.523604 -0.862127    ...    -1.657566  1.477833 -0.913008   \n",
       "18    -0.229361 -0.247615  1.300336    ...     1.142119  1.007354  0.752814   \n",
       "19     1.255251  0.526070  1.105921    ...    -0.337289  0.192494  1.828316   \n",
       "20     1.532119  0.013218 -0.858656    ...    -0.088662  0.150469  2.682788   \n",
       "21    -0.071371 -1.113551 -1.275093    ...    -0.422841 -0.987524  1.748075   \n",
       "22     2.202473 -1.263990 -0.492838    ...    -0.488526  1.296895  1.519787   \n",
       "23     0.135511  0.700605  2.155847    ...     1.240510  1.075392  1.209142   \n",
       "24     0.210559  0.029388 -0.089877    ...     1.166199 -0.024558  2.028121   \n",
       "25    -0.789251  0.534989  0.645842    ...     1.782632  0.565539  1.427701   \n",
       "26     0.817371  0.160823 -0.477412    ...    -0.492614 -0.483204  0.679723   \n",
       "27     2.492505 -1.337085  0.250375    ...     0.359694  1.687578 -0.658343   \n",
       "28     0.402709 -0.834813 -1.623028    ...     0.255448  0.291791  0.380609   \n",
       "29    -1.076968  0.286743 -1.826256    ...    -1.759138  0.253365 -0.359285   \n",
       "...         ...       ...       ...    ...          ...       ...       ...   \n",
       "470   -0.047282  0.670949 -0.776838    ...    -0.494400 -0.018289  1.533713   \n",
       "471   -0.808346  0.309479 -0.269975    ...    -0.073112  0.737225  1.346217   \n",
       "472   -1.180093 -0.210127  1.381785    ...     0.281706 -0.674630  1.627711   \n",
       "473    1.568725 -0.833717  0.607353    ...     0.469496  0.271537  0.638085   \n",
       "474    0.592363  0.383519  1.374765    ...    -0.215889  0.376747  0.936373   \n",
       "475   -0.022819 -0.848305 -0.702388    ...     1.105312 -0.185239 -0.158070   \n",
       "476    0.328154 -0.341631  0.831014    ...    -1.536445 -2.564477 -0.234192   \n",
       "477   -1.959668 -1.077590 -1.954408    ...     0.077934 -0.226854 -0.326672   \n",
       "478    0.279478 -0.246831 -0.873831    ...    -0.060307 -1.899385 -0.254404   \n",
       "479   -0.964631 -1.194054 -1.362640    ...    -1.725553 -0.875762  0.355848   \n",
       "480    0.260590 -1.758692 -0.044246    ...     1.374209  1.215865  0.719087   \n",
       "481    1.836281 -1.191013  0.347430    ...    -1.313130  0.859501 -1.830169   \n",
       "482   -0.636984 -0.875119 -1.161587    ...    -1.355296  0.047962 -0.096390   \n",
       "483    0.274370  0.534668  0.901013    ...    -1.175760 -0.470270  0.725103   \n",
       "484   -0.505417 -1.275018  0.588087    ...    -0.508914 -1.878868 -0.357748   \n",
       "485   -0.334945 -0.978257  1.414944    ...    -1.482976 -0.443699 -2.747835   \n",
       "486    2.270370  0.191129 -0.401860    ...    -0.368457  1.730497  0.578539   \n",
       "487    0.942587 -0.626337 -1.096907    ...    -0.195443 -0.891175  0.058723   \n",
       "488   -1.158009 -0.570324 -1.092600    ...    -0.611624  0.487866  0.172767   \n",
       "489    0.368037 -1.491658  0.177186    ...     1.377023  1.115438 -0.146635   \n",
       "490    3.650623  1.682264  0.936215    ...    -0.843937 -0.339714 -0.409672   \n",
       "491    0.049615 -0.844883  1.662772    ...    -0.026685 -1.239547  0.193902   \n",
       "492    0.047947 -1.448027  2.168663    ...     0.310410 -0.523617  0.295704   \n",
       "493    1.257188  0.446759 -0.717149    ...     1.628739 -0.176509 -2.643964   \n",
       "494   -1.118633 -0.037854  1.027436    ...    -1.442001  0.192543 -2.150644   \n",
       "495   -1.462313 -0.388814 -2.353651    ...     1.739201  1.235095  0.275328   \n",
       "496    0.557816  0.635095 -0.232625    ...    -0.609539  0.208579 -2.033640   \n",
       "497   -0.131147  0.203176  0.578609    ...     0.475324 -0.266354 -0.566444   \n",
       "498    2.552551 -0.521071  1.339807    ...     0.110808  0.810555 -0.908970   \n",
       "499   -0.982158 -0.720435 -3.568840    ...    -0.155850  0.538137 -0.769790   \n",
       "\n",
       "            193       194       195       196       197       198       199  \n",
       "index                                                                        \n",
       "0     -1.198301 -0.011830  1.537544 -0.772709 -0.140069  2.087113 -0.831155  \n",
       "1      1.218986 -0.318957 -0.644568 -0.006130 -1.237353 -1.329079 -1.326488  \n",
       "2      0.945877  0.142990 -0.198892 -0.039329 -0.586616  2.250676  1.492455  \n",
       "3      1.648818 -0.736264 -0.886601 -1.271747 -0.149291  0.200660 -1.481958  \n",
       "4      1.131444 -0.423028 -0.268517  0.304515 -1.224529 -1.942150  1.518630  \n",
       "5      1.259737  0.313092  0.479246  1.332200 -0.735397  0.978559 -0.822000  \n",
       "6     -0.944889 -1.078897 -0.801034  0.269001 -1.709661  0.382265  0.537923  \n",
       "7      1.625088 -0.476602 -1.179684  0.232037  1.838190 -0.704720  0.876326  \n",
       "8      0.605970 -1.287595  0.019271 -0.132577  0.957579  1.284221 -0.678374  \n",
       "9      0.272462  1.383491  0.963489  0.870056 -0.131865 -0.116000  0.272825  \n",
       "10     2.097841  0.168282  1.873597  1.529014  0.207111 -0.017888  0.961969  \n",
       "11     0.827838 -0.548445  0.447461  0.552537 -1.183448  1.029311 -0.780909  \n",
       "12    -0.448502 -1.497480  1.033743 -0.461447  0.722109  0.194513  1.135791  \n",
       "13    -1.969990  1.037509 -0.122944 -0.021804 -0.609123 -0.207297 -1.361811  \n",
       "14     1.233520  0.023018  0.571407 -2.039363 -0.576561  0.079145 -1.197674  \n",
       "15     0.151129 -0.123127  0.778205 -0.874226  0.281296 -1.210919 -0.091103  \n",
       "16    -0.641697  0.442236 -1.086310 -2.178310  0.168934 -0.092904  0.811843  \n",
       "17     1.362358 -1.118084  0.074183  0.263447 -1.826516 -0.351224 -0.299599  \n",
       "18     0.409072  1.581266 -0.154616 -1.009337 -0.209094  0.696452  1.666319  \n",
       "19    -1.218853  0.130257  2.910900  0.456515  2.040317  0.080433  0.819483  \n",
       "20    -0.768501  1.122346  0.063651 -0.198887  0.987199  0.485552  2.035827  \n",
       "21    -1.574052  1.264796  0.259914  0.544842  0.779822 -0.180305 -0.114592  \n",
       "22    -1.071912  0.918177 -0.080344 -0.179744 -0.692400  0.642983 -1.186788  \n",
       "23    -0.403709  0.652131  1.998386 -1.655288 -0.375074 -2.050110  0.034512  \n",
       "24     0.525236 -0.510688 -0.486759  0.806610  0.833828 -0.642634  1.688117  \n",
       "25    -0.146075 -0.774683 -0.177307  0.041243 -0.041427 -0.401074 -0.886501  \n",
       "26    -1.162005  1.431226  0.440273 -1.091537 -2.037076 -1.875155 -0.008665  \n",
       "27    -0.877079 -1.550752  0.470490 -0.125226 -1.165412 -0.051151  0.409614  \n",
       "28     0.061646 -1.092998  0.963629 -1.303065 -0.991181  1.252048 -1.161991  \n",
       "29     0.314776  0.909865  0.862814 -1.369782  0.429608  0.784438 -0.077056  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "470   -1.213655  0.124575 -1.231166  0.225322  1.325321  0.070505 -0.391708  \n",
       "471   -1.737192 -1.013179  2.118034  1.640718  1.052812  0.697189  0.625568  \n",
       "472   -0.476788  0.352119  0.394137  0.052393  1.709851 -0.494264  0.144678  \n",
       "473   -1.358878  0.159311 -0.281003 -0.408173 -0.195773  1.925356 -0.257296  \n",
       "474   -1.179268 -0.661063  2.244349 -0.303157  0.854584 -0.841527 -0.394065  \n",
       "475    1.089971 -0.857535  2.080588 -0.285347  0.072800  1.640151  0.809219  \n",
       "476    0.623118  1.754201 -0.837495  1.879102  1.388051 -0.760446  0.528030  \n",
       "477   -0.539372  0.238348  0.314608 -2.203816  0.329200  0.542399  1.389343  \n",
       "478   -0.433326 -1.633942  0.777557  0.488686 -0.117312 -1.234208  0.615680  \n",
       "479    0.393084 -0.892655 -0.199977 -1.698224 -0.530143 -0.100622  0.786532  \n",
       "480    0.336805  0.639550 -0.528596  0.813380  0.903790  0.859407 -0.667846  \n",
       "481    1.510086  1.006010  1.450007 -0.428709 -0.353205 -0.141457 -0.166389  \n",
       "482   -0.089237  0.182282  0.834032 -0.546210  0.043812  1.795072  1.037416  \n",
       "483   -1.446059  0.166252 -1.213046 -0.686100 -1.946530  1.051437  0.597908  \n",
       "484    0.176305  0.435865  0.223716  1.234651 -0.518015  0.592277  0.124244  \n",
       "485   -0.351952  0.731784 -0.639598 -1.115431 -0.403971  1.116513  1.140286  \n",
       "486    1.437438  0.186362 -0.052468  0.012282  0.516301 -0.725883  0.769331  \n",
       "487   -0.391545  0.227356 -1.679019  0.449165 -0.178523  0.283603 -1.019215  \n",
       "488   -0.669769  1.601192  0.353912  2.325475  0.253087  0.276432 -1.004216  \n",
       "489    1.869824 -1.169580  0.523679 -2.392640 -0.728643  1.001824 -2.619280  \n",
       "490    0.024755 -0.514596 -0.513056  0.168732 -0.813216 -0.756909 -0.013165  \n",
       "491    0.806774 -1.535845 -1.671239 -0.698848 -0.988954  2.477496  1.997063  \n",
       "492   -0.780874  1.330365 -0.445954 -1.375572  0.852129  0.409654  1.137497  \n",
       "493   -0.021249 -1.280983 -0.638719 -1.077257  0.642512 -1.342502  0.522688  \n",
       "494   -0.347355  0.045971 -0.294138 -0.482686 -0.283465  0.983899  1.742714  \n",
       "495    0.582903 -0.549433  0.460677  1.218235  0.102455  3.003444 -0.034359  \n",
       "496   -0.107492  0.899276 -0.422913  0.397747 -0.080801 -1.705400 -0.478646  \n",
       "497    0.849093  0.746858  0.207070 -1.009005  0.331707 -1.751323 -0.539687  \n",
       "498   -0.013028  0.148263  0.501929 -0.001994 -1.664151  2.511700 -0.011796  \n",
       "499   -0.358702 -0.312090 -0.763049  0.652486  0.616117 -0.090219 -1.021522  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "5           1\n",
       "6           0\n",
       "7           0\n",
       "8           1\n",
       "9           0\n",
       "10          1\n",
       "11          1\n",
       "12          0\n",
       "13          0\n",
       "14          1\n",
       "15          0\n",
       "16          0\n",
       "17          1\n",
       "18          0\n",
       "19          1\n",
       "20          0\n",
       "21          0\n",
       "22          0\n",
       "23          1\n",
       "24          0\n",
       "25          0\n",
       "26          0\n",
       "27          1\n",
       "28          0\n",
       "29          1\n",
       "...       ...\n",
       "470         0\n",
       "471         0\n",
       "472         1\n",
       "473         0\n",
       "474         1\n",
       "475         1\n",
       "476         1\n",
       "477         1\n",
       "478         1\n",
       "479         0\n",
       "480         0\n",
       "481         1\n",
       "482         1\n",
       "483         0\n",
       "484         0\n",
       "485         1\n",
       "486         1\n",
       "487         0\n",
       "488         0\n",
       "489         1\n",
       "490         1\n",
       "491         0\n",
       "492         1\n",
       "493         0\n",
       "494         0\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como nmeros (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 1. \n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = sklearn.model_selection.train_test_split(X, y, test_size=0.2, stratify = y)\n",
    "\n",
    "# Objetivo: variables X_dev, X_eval, y_dev e y_eval asignadas\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dev: (400, 200), y_dev: (400, 1) para desarrollo\n",
      "X_eval: (100, 200), y_eval: (100, 1) para evaluacin\n"
     ]
    }
   ],
   "source": [
    "print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "print(\"X_eval: {}, y_eval: {} para evaluacin\".format(X_eval.shape, y_eval.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribucin de y.\n",
    "plt.title('Dev Set')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(np.array(y_eval))  # muestra un histograma para la distribucin de y.\n",
    "plt.title('Hold-out Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ejercicio 2\n",
    "\n",
    "Entrenar un rbol de decisin con altura mxima 3 y el resto de los hiperparmetros en default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol_2_1 = DecisionTreeClassifier(max_depth=3)\n",
    "arbol_2_1.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = arbol_2_1.predict_proba(X_eval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_eval, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XtYVVX6wPHvK3gHTRG8Cyp4AbQyNC+peSmzLKupGbtYFmpq9puZasqyGiuzLE3TNLWyTLs7WjY5WVOajWWKWeZdRPAuoIDihev6/bE3dCIEVA77HM77eR4ezzl7nbPfBcf97rX22muJMQallFIKoIrTASillPIcmhSUUkoV0qSglFKqkCYFpZRShTQpKKWUKqRJQSmlVCFNCpWMiPxHRO4uQ7lMEWlVETGVJxG5TkQWOx3H2YjIcBFZ5abP7i8iie74bJd91BSRHSIS5M79KM+lScEBIpIoIqdF5ISIpIvI9yIySkQu+O9hjBlojFlQhnIBxpiEC9mXiGyxk0umiOSJyBmX549fyGeX4DngBTd9tscQEX8RMSIS5obPfkhE9ojIcRE5ICJTRcQfwBhzGlgAPFLC+yeKSI79d04XkTUi0qVImfoiMkdEjojIKRHZJCJ3FfNZQ0Vkg4icFJFDIvK5iHQv7zqrstOk4JzrjTGBQCjWQe5R4E1nQzo3xpgoO7kEAN8BYwueG2MmFS1fcOA5XyLSDahujIm7kM9RfAJcYoypA1wMxABjXLa/C9wjIlVL+Ix37b97MNbf/uOCDSJSHfgaaAZ0AS4CxgFTReT/XMo9AkwBnrU/JxSYBwy+0AqW5EK/h5WdJgWHGWMyjDHLgL8Ad4tINFj/sURkiojstc+25ohIzYL3ichgEfnZPtvbLSLX2K+vEpHh9uNwEflWRDJEJFVEPnR5vxGRcPtxXRF5R0RSRCRJRJ4oaLWIyDAR+Z8dS5p9hjmwLHWzu1JWi8gMETkGPOHy+nb78/4jIs1d3hMpIv8VkWN2mT+5fORA4FuXsgVn06Pt38EJEfmniESIyFr7d/N+wcFNRIJEZLldzzQR+UxEmtrbGojIQRG51n4eaNf19lLqGCwi/7b3tRZoWWT7WesjIotEZJaIfG3HvtLld7Ha/regNeb6vkfsOhws7uy7NMaY3caYDJeX8oFwl+1JwEmsA3ppn5UDvAe0EJF69svDgMbAn40xScaYbGPMcuBvwEQRCbDLTgBGGWM+Mcacsst9aox5tLh9iUgtEZlm/5/IsL9b1aWYbjUR2S8iV9qPJ4rIh/Z34QTwmN16qetSvrOIJBckjJK+o5WeMUZ/KvgHSAT6F/P6XmC0/Xg6sAyoDwQCnwHP29u6ABnAVViJvSnQzt62ChhuP34fGG+XqQFc4bIvA4Tbj98BPrX3EwbsBGLtbcOAHGAE4AeMBg4CUiT2wv26vDYcyLXf4wfUBG4BdgBtAX+sA8N3dvlA4ABwl73tMuAo0NbevhT4u8vn+9v1WGK/tyOQDXxl16MesB24wy4fDNxkx1HHft9il88bCBwCGgBvAR+U4W+52P4917L3fwhYVcb6LLL/jj2A6sAsl/cW1C3MZV/97d/nP4GqwA1YB+869vbxQPpZflKLxD0UOGHvIxmILrJ9OTDmLHWeCLxtP66OdbafDPi5/E7eLOZ91bESUD9gkP238juH/zdzsVogje3v0xX276E/kFik7H7gSpd4s4Hrsf4v1MRKuve4lJ8GvGo/Put31Bd+HA/AF384e1JYa//HFvs/e2uXbd2APfbjucC0s3z2Kn5LCu9gNcebFVPOYJ0d+gFZQKTLtvtcDk7DgHiXbbXs9zY6235dXhsOJBR57Svgbpfn/vb+mwJ3ACuLlH8TGG8/Xum6D347cF7u8tovwEMuz18BppzldxUDpBR57TXgV/ugUq+Uv2NVrIN0uMtrL7r87kqrzyJgkcu2ulgHzcacPSlk4nIgBY4BMRfwXWyL1X0TUuT1D4HHz/KegoNsOpAHpAC9inwXJp7lvanYrWJg/znEWfA9jSpmW1mSwjdFto8CvrQfV8E60ele2nf0fH/P3vSj3UeepSnWf/JgrIPvBrEu5KUDX9ivAzQHdpfh8x7BSjDrxLoofG8xZRoA1YAkl9eS7FgKHC54YIw5ZT8MKMP+AfYVeR4KzHKpVyrWgbCZva1HwTZ7+1+wDpIAaVhn30UdcXl8upjnAQAiUltE3rC7H44D32DV39U8IBrrTDetlLo1xDpYudbR9fdYWn1wfa+xunQygCYl7DPVGJPn8vwUZf9b/IExZgfWWfGrRTYFYh30z+Y9Y8xFQCP7/Ze6xsjv6wgUXmuob28/CoRI2QdXNMT6npble1+cot/Dj4GeItIQ6AOcMcZ8b28r6Tta6WlS8BAi0hnrQPw/rC/haayzoovsn7rGurAH1he8dWmfaYw5bIwZYYxpgnX2P7vgOoKLVKzuoVCX11pgdXuUh6LT8O7D6pq6yOWnpjHmR3vb10W2BRhjxtrv3QS0uYBYHsHq8+9irIusfV032v3Jc7FG3zwgpQ/ZPYJ1sHDtb27h8ri0+uD6XruPuy7WWes5T18sIk/Kb6O/iv6UdID354/fp/ZYra4SGWNSsL5bE+0DLMB/getEpFaR4rdgtYDXAWuwWlk3lF4zwPpdZxcTJ/ZnFu7L/jsWHVL7u9+nMeYo1knBrcDtWF2ABUr6jlZ6mhQcJiJ1RGQQ8AFWV8Kvxph84HVgmoiE2OWaisgA+21vYo0O6SciVext7Yr57FtFpODsJg3rP4brWSb2WedHwHP2xdVQ4EGsrg13mAOMF5H2dowXicgt9rZlQJSI3C4iVe2fLiLS1t6+HOh9AfsOxDqzThNrHP5TRbY/idVNcC/WNZ0FJZ3JGusi6yfA02KN74/G6qsvUFp9AK4XkW72WfRE4H/GmEP23+UoUOZ7SYwxz5rfRn8V/bmooJyIjHD5XkVhjXz72mV7C6zWx/oy7neL/f6H7ZcWYB3EPxSRULveA7H67Z8yxpywW2FPA6+JyA3276+qWPeh/GHIsf37eBuYLiKNRMRPRHqINYhgOxAoIgPs5wXXXErzHlY31s324wIlfUcrPU0KzvnMHgmxD+s6wsvAPS7bHwXigbV2V8d/sfp/Mcass8tOw+pu+Jbfn+kX6Az8KCKZWAeovxpj9hRT7gGss60ErJbKe8D8C61gcYwxH2PV9WO7XpuAAfa2DPvxnVgXbA8Dz2NdoCyod5aIXHaeu38Z60z8KPA98J+CDWKNs38AuMtOypOwuiv+Ucpnjsa6oH0EK1m/5VLXEutjW4SVDFKxLlS7JpV/Au/Z3Rg3n2NdS9IL2CwiJ4F/Y303nnTZfgfwljEm+xw+8yVgtIg0MNa9Dn2x6rseOI51reVRY8y0gjcYYyZjfc8nYP1N9mH9Pj85yz7+DmwDNmB1s07CGvCQhvW3W4DVwj2GS5dnCT4BIoG9dmIriOus31FfIPaFFKW8glhDRu81xnj9mZuILMK6iD/B6VgKiDXs+WeghzEm1el4VMXTmziUVzHWePflTsdRWdln+W1LLagqLe0+UqoUYs0FVNzF2784HZtS5U27j5RSShXSloJSSqlCXndNoUGDBiYsLMzpMJRSyqts2LAh1RgTXFo5r0sKYWFhxMXpJJlKKXUuRCSp9FLafaSUUsqFJgWllFKFNCkopZQqpElBKaVUIU0KSimlCrktKYjIfHt5u81n2S5iLdMYL9ai3p3cFYtSSqmycWdL4W3gmhK2DwQi7J+RWCteKaWUcpDbkoIxZjXWFLZnMxh4x1jWAheJyB9Wa1JKKV93IjOTR95fS2LqSbfvy8lrCk35/RJ5+/n9EpCFRGSkiMSJSFxKSkqFBKeUUp7gm2++oeNN9/PRL0f5IcH9s5k7mRSkmNeKnZ3PGDPPGBNjjIkJDi71Lm2llPJ66enpjBgxgqtvGoLpeANRQX4M6dyi9DdeICenudjP79e2bYa1Nq1SSvm0vLw8unfvzo4dO+j88Nscr1abObG9ECnuXLp8OdlSWAbcZY9C6gpkGGMOORiPUko56ujRoxhj8PPz47nnnuOFD1dxWOoz7tp2NK9fq0JicOeQ1PeBH4C2IrJfRGJFZJSIjLKLLMdaEzgea5H6Me6KRSmlPJkxhkWLFtGmTRveeOMNALr3G8jCzafoElafOy8vbgl293Bb95Ex5rZSthvgfnftXymlvMG+ffsYNWoUy5cvp2vXrvTo0QNjDOOXbiYrN5/Jt3SkShX3dxsV0DualVLKIe+//z5RUVGsWrWK6dOn87///Y/IyEg+23SI/247wsNXt6Vlg9oVGpPXraeglFKVRb169bj88suZN28eLVu2BOBoZhYTlm3h4uYXce8VLSs8Jk0KSilVQXJzc5k2bRrZ2dmMHz+eK/tdRfOO3diUnMmSL3ew60gmvx7IIPNMLi/d0hG/Cuw2KqBJQSml3OxkVi7/WbORCdPmcOBEHqEduvLliyvZl3aKfPvuLL8qQmhQLaKb1uGmS5vRpmGgI7FqUlBKqXKScTqH+ORM4pNPsOtIJruSM9l15AQHM85YBaJupr4YGoYEEt4wkJs6NSU8JICIkEDCGtSiur+fsxVAk4JSSp2zo5lZ7ErOtBNAJrvsJJB8IquwTHX/KoSHBNCmnh/bP19Et8iWPPOPMVzcqgn+fp47xkeTglJKFcMYQ/KJLOugf+SEddZvJ4FjJ7MLy9Wu5kd4w0B6tQkmIiSA8JAAmgRUIe7bLxl650AAEq5uQatWrZyqyjnRpKCU8mn5+YaDGad/O+s/Yp/5J2dy4kxuYbm6NasSERLAgKiGhIcEFiaAxnVr/G76ia+++oprR44kKSmJmMs60b59e69JCKBJQSnlI/LyDfuOnSo829+VfKIwEZzKziss1yCgGuEhAdx4SVMiGloH/vCQAIIDqpc491BaWhoPP/ww8+fPp02bNnz77be0b9++IqpWrjQpKKUqlZy8fJKOnmTXkYKDv/WzOyWT7Nz8wnKN6tQgomEAf+ncnIiQQCsBBAdQr3a1c95nXl4ePXr0YOfOnTz22GM89dRT1KhRozyrVWE0KSilvNKZnDz2pJ50ueBrXezdk3qS3PzfZuFvVq8mESEB9IxoYI/0CaB1SAB1alS94BhSU1OpX78+fn5+TJo0iRYtWtCpk3evLKxJQSnl0U5l57I7+WRhP39Bl0/S0ZOFY/yrCIQG1SY8JICrIhsS0dAa5tkquDa1qpX/Yc4Yw8KFC/nb3/7GCy+8wMiRI7nxxhvLfT9O0KSglPIIx8/YY/yP/Nbfvys5k/1ppwvLVPUTWjaoTfvGgVx/cRMiQgKIaBhAWFBtalStmDH+SUlJ3HfffaxYsYLu3bvTq1evCtlvRdGkoJSqUGkns+1+/hOF/f7xyZkcPn6msEx1/yq0Dg6gU4t6/CWmuX3BN5DQoFpUdXCM/6JFixg9ejTGGGbOnMmYMWOoUsVz7zk4H5oUlFLlzhhDSmaWfdb/WwLYnZJJauZvY/xrVfMjIiSA7uFB1sVe+8y/Wb1ajsz7U5rg4GB69OjB3LlzCQ2tuDUOKpJYyxp4j5iYGBMXF+d0GEoprIP/oYwzhdM5xLvc4JVxOqewXGANf9o0DCQ8OKBwmGdEw0Aa16lRoWsFnKucnBymTp1KTk4OTz75JGDVuSKWxSxvIrLBGBNTWjltKSilSpWXbziQdrrwYq/V7WMlgZMuY/yDaltj/Ad1bGyf9Vtn/8GBJY/x90QbN24kNjaWjRs3MmTIkMJk4G31OFeaFJRShXLz8kk6dqrwoF+QAHanZJLlMsa/YZ3qRIQEcmtM88JhnuEhAQQFVHcw+vJx5swZnnnmGV588UUaNGjAv/71L26++Wanw6owmhSU8kFZudYY//jCs36r339P6kly8n7rUm56UU0iGgbQIzzIvrM3kPCQAOrWvPAx/p4qPj6eKVOmcNdddzF16lTq1avndEgVSpOCUpXY6ew8dqf8fibP+ORMko6dIs8e5F9FoEX9WoSHBNKvfcPCfv/WwQHUru4bh4jMzEyWLl3K0KFDiY6OZseOHYUrofka3/iLK1XJnSgY45/sOrXDCfannaZgLIl/FSGsQW3aNgpkUMfGhNsXflsFV9wYf0+0YsUKRo4cyb59+4iJiaF9+/Y+mxBAk4JSXiX9VLbLhd7fbvI6lPHbGP9q/lVo1aA2lzSvx62XNS/s7w8Nqk01/8o1pv5CHD16lAcffJB33nmHdu3a8d1333nlBHblTZOCUh7GGENqZvbvZvEsWMUrNfO3RVxqVvUjPCSAbq2CCLendQgPCaB5vZoevYiLJyiYwC4+Pp7x48fzxBNPeO0EduVNk4JSDjHGcPj4mcIDfuGkbsmZpJ9yGeNf3Z/whgH0bRdsHfgbWqN9mtSt6dFj/D1RSkoKQUFB+Pn5MXnyZEJDQ7nkkkucDsujaFJQys3y8w0H0k//7kJvQRLIzPptEZd6taoSERLItR3sMf72dM4hXjjG39MYY3j77bd58MEHeeGFF7jvvvsYPHiw02F5JE0KSpWT3Lx89ros4uLa538m57cx/iGB1QkPCeBPnZoSbt/cFVFJxvh7osTEREaOHMlXX31Fz5496dOnj9MheTRNCkqdo+zcfBLtRVwK7vDdnZxJQspJsvN+O/g3vagmrUMCuOPyoMI5fcKDA6lbq/KO8fc0CxcuZPTo0YgIs2fP5r777qt0E9iVN00KSp1FXr5h++Hjv1u3Nz45k8Sjv43xl4Ix/sEB9G4bXDipW+uQAAJ8ZIy/J2vYsCG9evVizpw5tGjRwulwvIJOiKdUMQ6mn2bsez/x0950APyqCGFBtewpHQILJ3VrHRzg02P8PU1OTg4vvvgieXl5PPXUU06H41F0QjylztO3O1P42wcbyc7N59kbo7m8ZX3CdIy/x/vpp5+49957+eWXX7j99tu9djZTp2lSUMqWl2945b87mbkynjYhgcy+sxOtgwOcDkuV4vTp0zz99NNMmTKF4OBgli5dWmmWxnSCW099ROQaEdkhIvEiMq6Y7S1EZKWIbBSRTSJyrTvjUepsUjOzuGv+j8z4Jp6bL23GJ/f30ITgJRISEnj55ZcZNmwYW7du1YRwgdzWUhARP2AWcBWwH1gvIsuMMVtdij0BfGSMeU1EIoHlQJi7YlKqOOsTjzH2vZ9IP5XD5D914M8xzbXbwcMdP36cJUuWMGzYMKKioti1a1elXQmtormzpdAFiDfGJBhjsoEPgKJ3ixigjv24LnDQjfEo9TvGGOZ+u5sh89ZSs6ofS8f04C+dW2hC8HDLly8nOjqa2NhYtm3bBqAJoRy5Myk0Bfa5PN9vv+ZqAnCniOzHaiU8UNwHichIEYkTkbiUlBR3xKp8TMapHEa8s4Hn/7OdqyMbsuyBK4hsUqf0NyrHpKamMnToUK677joCAwNZs2aNTmDnBu680Fzc6VbR8a+3AW8bY6aKSDdgoYhEG2Pyf/cmY+YB88AakuqWaJXP+HV/BmPe28Ch9DM8NSiSe3qEaevAwxVMYJeQkMBTTz3F448/TvXqege4O7gzKewHmrs8b8Yfu4digWsAjDE/iEgNoAGQ7Ma4lI8yxvDuj3t55rOtBAVU48P7unFZqG+tquVtjhw5QnBwMH5+fkyZMoXQ0FA6duzodFiVmju7j9YDESLSUkSqAUOAZUXK7AX6AYhIe6AGoP1DqtydzMrlbx/+zBOfbKZr6yA+/7+emhA8mDGGN998k7Zt2zJv3jwArr/+ek0IFcBtLQVjTK6IjAVWAH7AfGPMFhF5BogzxiwDHgJeF5G/Y3UtDTPedou18ni7jpxg9Ls/kZCSyUNXteH+PuE65bQHS0hIYMSIEXzzzTf07t2b/v37Ox2ST3HrzWvGmOVYF5BdX3vK5fFWoIc7Y1C+benG/Ty+ZDO1q/uxKPZyuoc3cDokVYIFCxYwZswY/Pz8mDNnDiNGjNAJ7CqY3tGsKqUzOXk88++tvPfjXrqE1Wfm7ZfSsI6urOXpmjRpQt++fXnttddo1qyZ0+H4JE0KqtLZe/QUY97bwOYDxxnVuzUPX91Gl6f0UNnZ2bzwwgvk5+czYcIErrrqKq666iqnw/JpmhRUpbJiy2Ee/vgXBHj9rhiuimzodEjqLNavX8+9997L5s2bGTp0qE5g5yH09ElVCjl5+Tz3+VbuW7iBsKDafP5/PTUheKhTp07x8MMP07VrV9LS0li2bBnvvPOOJgQPoS0F5fUOZ5xh7Hs/EZeUxtCuoTwxqD3V/XWNA0+1Z88eZs6cyYgRI5g8eTJ169Z1OiTlQpOC8mr/25XKXz/YyOmcPF4ZcgmDLyk6k4ryBBkZGSxZsoR77rmHqKgo4uPjad68eelvVBVOu4+UV8rLN0z/706Gzv+R+rWrsWxsD00IHurzzz8nKiqK4cOHs337dgBNCB5Mk4LyOkczsxj21jqm/3cXN13SlE/H9iA8JNDpsFQRKSkp3HHHHQwaNIh69erxww8/0K5dO6fDUqXQ7iPlVTYkHeP+dzdy7FQ2z9/cgSGdde0DT5SXl8cVV1zBnj17ePrppxk3bhzVqlVzOixVBpoUlFfIzcvn9e/2MPXLHTStV5Mlo7sT3VQvUHqaw4cPExISgp+fH1OnTiUsLIzo6Ginw1LnQLuPlMf7dX8Gg2etYfIX27kqsiHLxl6hCcHD5OfnM3fuXNq0acPcuXMBGDRokCYEL6QtBeWxTmXn8vKXO5m/Zg9BAdV57Y5OXBPdSLuLPEx8fDwjRoxg1apV9O3blwEDBjgdkroAmhSUR/p2Zwrjl/7K/rTT3H55Cx69ph11a1Z1OixVxFtvvcWYMWOoVq0ar7/+OrGxsZq0vZwmBeVRUjOzePbfW/n054O0Dq7NR/d1o0vL+k6Hpc6iRYsWDBgwgFmzZtG0qQ4Jrgw0KSiPYIzhXz8dYOLnWzmZlctf+0Uwpk9rvTPZw2RlZfH888+Tn5/PM888Q79+/ejXr5/TYalypElBOS7p6EkeX/ora+KPEhNaj+dv7kBEQ73vwNP8+OOPxMbGsmXLFu6++26dwK6S0qSgHJOTl88b3+1h+n93Us2vChNvjOb2Li10VTQPc/LkSZ588kmmT59O06ZN+fe//811113ndFjKTTQpKEf8si+dcUt+Zduh41wT1YgJN0TRqK4uguOJkpKSmD17NqNGjeKFF16gTp06Toek3EiTgqpQJ7NymfrlTt7+fg/BgdWZO/QyBkQ1cjosVUR6ejqLFy9m+PDhREZGEh8fryuh+QhNCqrCrNyezBOfbOZA+mnu7NqCR65pR50aOszU03z66aeMHj2a5ORkrrjiCtq1a6cJwYfoHc3K7VJOZPHA+xu55+311Krmx+JR3Zh4YwdNCB4mOTmZIUOGcOONNxIcHMzatWt1AjsfpC0F5TbGGD6O289zy7dxOjuPv/dvw6grW+kwUw+Ul5dHjx492Lt3LxMnTuSRRx6halVN2r5Ik4Jyiz2pJ3lsySbWJhyjS1h9Jt3cgfCQAKfDUkUcPHiQRo0a4efnxyuvvEJYWBiRkZFOh6UcpN1Hqlzl5OUza2U8A6avZsvB4zx/cwc+GNlVE4KHyc/P57XXXqNdu3bMmTMHgGuvvVYTgtKWgio/G/em8diSX9l++ATXdmjEhOujCKmjw0w9zc6dOxkxYgSrV6+mf//+DBw40OmQlAfRpKAuWGZWLlNW7GDBD4k0qlOD1++K4arIhk6HpYrx5ptvMnbsWGrUqMH8+fMZNmyY3pWsfkeTgrogX287wpOfbObQ8TPc1TWUhwe0JVBHFXmssLAwBg4cyKxZs2jcuLHT4SgPpElBnZfkE2d4etlWPv/1EG0bBvLqHZ3o1KKe02GpIrKysnj22WcBmDhxok5gp0qlSUGdk/x8w4dx+3h++TbO5ObzjwFtGdGzFdX8dcyCp/n++++JjY1l+/bt3HvvvTqBnSoTTQqqzHanZPLYkl9Zt+cYXVvVZ9JNHWgVrKOKPE1mZibjx49n5syZNG/enC+++EJXQ1Nl5tbTOxG5RkR2iEi8iIw7S5k/i8hWEdkiIu+5Mx51frJz85nx9S4GTv+O7YeOM/lPHXh/RFdNCB5q7969zJ07l/vvv5/NmzdrQlDnxG0tBRHxA2YBVwH7gfUisswYs9WlTATwGNDDGJMmIiHuikedu9PZeXy4fi/zVidwMOMMgzo25qnrIwkJ1GGmniYtLY2PP/6YkSNHEhkZSUJCAk2aNHE6LOWF3Nl91AWIN8YkAIjIB8BgYKtLmRHALGNMGoAxJtmN8agyOn4mh4U/JDH/f3s4ejKbLi3rM/mWjvSMCHY6NFWMpUuXMmbMGFJSUujduzdt27bVhKDOmzuTQlNgn8vz/cDlRcq0ARCRNYAfMMEY80XRDxKRkcBIsNaEVe6RmpnF/P/tYeEPSZzIyqVP22DG9Amnc5iukeyJDh8+zAMPPMDixYu55JJL+Pzzz2nbtq3TYSkv586kUNwwB1PM/iOAK4FmwHciEm2MSf/dm4yZB8wDiImJKfoZ6gIdTD/NvNUJfLB+L1m5+VzboTGje7cmumldp0NTZ5GXl0fPnj3Zt28fkyZN4uGHH9YJ7FS5cGdS2A80d3neDDhYTJm1xpgcYI+I7MBKEuvdGJey7U7JZM6q3SzdeACAmzs15b7erWmtF5A91v79+2nSpAl+fn7MmDGDli1b6vTWqly5c/TReiBCRFqKSDVgCLCsSJlPgD4AItIAqzspwY0xKWDzgQzuf/cn+r/8LZ9tOsidXUP59pE+vHjLxZoQPFR+fj4zZ86kXbt2vPbaawAMHDhQE4Iqd25rKRhjckVkLLAC63rBfGPMFhF5Bogzxiyzt10tIluBPOAfxpij7orJ161PPMaslfGs2pFCYHV/xlzZmnt6tKRBQHWnQ1Ml2L59O8OHD2fNmjUMGDCAQYMGOR2SqsTEGO/qoo+JiTFxcXFOh+E1jDF8uzOF2St3sy7xGEG1q3HvFS0Z2i1UVz7zAm+88QZjx46lVq1aTJ8+naFDh+pdyeq8iMgGY0xMaeX0juZKKi/fsGLLYWatjGfLweM0qVuDCddH8pfOLahZTVdlXtLZAAAbiUlEQVQ+8xatW7fm+uuv59VXX6VhQ515VrmfthQqmZy8fD7ZeIDXvt1NQspJWjWozagrW3PjJU11fiIvcObMGZ555hkAJk2a5HA0qjLRloKPOZOTx4fr9zFvdQIH0k8T2bgOs27vxDXRjfCrot0N3mDNmjXExsayY8cOhg8frhPYKUdoUvByx8/ksGitdfdxamY2MaH1mHhTNFe2CdYDipc4ceIEjz/+OLNmzSI0NJQVK1Zw9dVXOx2W8lGaFLzU0cws3lqTyIIfEjlxJpdebYIZ2yecLi317mNvs3//ft544w0eeOABnnvuOQICdFiwco4mBS9zMP00r3+XwPvrrLuPB0Y3YnTvcDo007uPvcnRo0f56KOPGD16NO3btychIUFXQlMeQZOCl9iTepI5q3azZON+jIEbL23KqN6tCQ/Rs0pvYozhX//6F/fffz/Hjh2jb9++tG3bVhOC8hiaFDzc1oPHmb0qnuW/HqKqXxVu79KCEb1a0axeLadDU+fo0KFD3H///SxdupTLLruML7/8UiewUx5Hk4KH2pB0jFkrd/PN9mQCqvtzX+/W3NujJcGBevexNyqYwO7AgQO8+OKL/P3vf8ffX//7Kc9T4rdSRKoAXY0x31dQPD7NGMN3u1KZtTKeH/cco16tqjx8dRuGdgujbk29+9gb7du3j6ZNm+Ln58esWbNo2bIlbdq0cTospc6qxLuZjDH5wNQKisVn5ecbvth8iBteXcNd89eRdPQUTw6KZM24voztG6EJwQvl5eUxY8aM301gN2DAAE0IyuOVpf36pYj8CVhivO32Zw+Xk5fPsp8PMntVPLtTThIaVIsXbu7ATZ2aUt1fp6LwVtu2bSM2NpYffviBgQMHcv311zsdklJlVpak8CBQG8gTkdNYi+cYY0wdt0ZWiZ3JyePjuH3M+da6+7hdo0Bm3HYp10Y3wt9Pp6LwZvPmzeOBBx4gMDCQhQsXcscdd+hNhMqrlJoUjDGBFRGIr/hi82Ge+GQzqZlZdGpxEc/eGEWftiF64KgkIiIiuOmmm5gxYwYhISFOh6PUOSvT8AcRuRm4Ams5ze+MMZ+4NapK6kD6aR766GdCg2oz87ZL6dqqviYDL3f69GkmTJiAiPDCCy/Qp08f+vTp43RYSp23UvsqRGQ2MAr4FdgMjBKRWe4OrLIxxvDYkl8xwNyhl9GtdZAmBC+3evVqLr74Yl588UUyMjLQS26qMihLS6E3EF1wkVlEFmAlCHUOFm/Yz+qdKTx9QxTN6+uNZ97s+PHjjBs3jtdee41WrVrx9ddf07dvX6fDUqpclOWq5g6ghcvz5sAm94RTOR05foZn/72VzmH1GNo11Olw1AU6ePAgb7/9Ng8++CCbNm3ShKAqlbK0FIKAbSKyzn7eGfhBRJYBGGNucFdwlYExhvFLN5OVm8/kP3Wkiq5t4JVSU1P56KOPGDNmDO3atWPPnj26EpqqlMqSFGoCA12eCzAZeNYtEVUyn206xH+3HeHxa9vRKlgnr/M2xhg++ugjHnjgAdLT0+nfvz9t2rTRhKAqrbIkBX9jzLeuL4hIzaKvqT86mpnFhGVbuLj5RcRe0crpcNQ5OnjwIKNHj2bZsmXExMTw9ddf6x3JqtI7a1IQkdHAGKCViLheQwgE1rg7sMpgwmdbOXEmh5du6ahLYnqZvLw8evXqxYEDB5gyZQp//etfdQI75RNK+pa/B/wHeB4Y5/L6CWPMMbdGVQms2HKYz345yENXtaFNQ73/z1skJSXRrFkz/Pz8mD17Nq1atSI8PNzpsJSqMGcdfWSMyTDGJBpjbjPGJLn8aEIoRcapHJ74ZDPtG9dh1JWtnQ5HlUFeXh4vv/wy7du3L5zA7uqrr9aEoHyOtofd4NnPt3LsZDZvDetMVZ3LyONt3ryZ2NhY1q1bx6BBg7jxxhudDkkpx+gRq5yt2pHM4g37GdW7FdFNdd1kTzdnzhw6depEQkIC7733HsuWLaNZs2ZOh6WUYzQplKMTZ3J4fMmvhIcE8EDfCKfDUSUomJKiffv23HrrrWzdupXbbrtNpx5RPk+7j8rRC//ZzqHjZ/jX6O7UqKrrIXiiU6dO8dRTT+Hn58fkyZPp3bs3vXv3djospTyGthTKyfe7U3n3x73E9mhJpxb1nA5HFWPVqlV07NiRqVOnkpmZqRPYKVUMTQrl4FR2LuP+9SuhQbV46Oq2ToejisjIyOC+++4rnNL6m2++YdasWdpVpFQxNCmUg6lf7mTvsVNM/lNHalbTbiNPc+jQIRYtWsTDDz/Mpk2bdL0DpUrg1qQgIteIyA4RiReRcSWUu0VEjIjEuDMed9iQlMb8NXsY2jWUrq2CnA5H2VJSUpg5cyYA7dq1IzExkZdeeolatXTacqVK4rakICJ+wCysyfQigdtEJLKYcoHA/wE/uisWdzmTk8cji3+hSd2aPDqwndPhKKxRRe+99x7t27fnoYceYufOnQAEBwc7HJlS3sGdLYUuQLwxJsEYkw18AAwuptyzwIvAGTfG4hYzvt7F7pSTPH9zBwKq60Aup+3bt4/rr7+eO+64g/DwcDZu3KgT2Cl1jtyZFJoC+1ye77dfKyQilwLNjTH/LumDRGSkiMSJSFxKSkr5R3oeft2fwdzVCdx6WTN6tdGzUKfl5uZy5ZVXsnLlSqZNm8aaNWuIiopyOiylvI47T2+LG9pROAZQRKoA04BhpX2QMWYeMA8gJibG8XGE2bn5/GPxLwTVrsYT1/2hR0xVoMTERJo3b46/vz9z586lVatWtGql05Qrdb7c2VLYj7V0Z4FmwEGX54FANLBKRBKBrsAyb7jY/Nqq3Ww/fILnbupA3VpVnQ7HJ+Xm5jJlyhTat2/P7NmzAejfv78mBKUukDtbCuuBCBFpCRwAhgC3F2w0xmQADQqei8gq4GFjTJwbY7pg2w8f59WVu7jh4iZcFamrbzlh06ZNxMbGEhcXx+DBg/nTn/7kdEhKVRpuaykYY3KBscAKYBvwkTFmi4g8IyJeua5zbl4+jyzeRJ0aVZlwg/ZXO2H27NlcdtllJCUl8eGHH7J06VKaNGnidFhKVRpuHTJjjFkOLC/y2lNnKXulO2MpD++v28um/Rm8evul1K9dzelwfIoxBhEhOjqaIUOGMG3aNBo0aFD6G5VS50THUZ6Dr7YlExESwHUdGjsdis84efIkTzzxBP7+/rz00kv06tWLXr16OR2WUpWWTnNRRnn5ho1JaXRuWV/nzKkgX3/9NR06dGD69OlkZWXpBHZKVQBNCmW088gJTmTl0jlMZ0B1t/T0dIYPH07//v3x9/dn9erVzJgxQ5OxUhVAk0IZxSWlARATWt/hSCq/I0eO8MEHH/Doo4/yyy+/0LNnT6dDUspn6DWFMopLPEZIYHWa1avpdCiVUkEi+Otf/0rbtm1JTEzUC8lKOUBbCmUUl5hGTFg97cIoZ8YYFi1aRGRkJI888gi7du0C0ISglEM0KZTB4YwzHEg/rV1H5Wzv3r1cd911DB06lLZt2/Lzzz8TEaFrWyvlJO0+KoO4pGMAxOhF5nJTMIFdcnIyM2bMYMyYMfj56QJFSjlNk0IZxCWmUbOqH+0b13E6FK+XkJBAaGgo/v7+vP7667Ru3ZqwsDCnw1JK2bT7qAziko5xSfOLqOqnv67zlZuby+TJk4mMjGTWrFkA9OvXTxOCUh5Gj3KlOJmVy7ZDJ/T+hAvw888/c/nllzNu3DiuvfZabr31VqdDUkqdhSaFUvy8L528fMNlYXqR+Xy8+uqrdO7cmQMHDrB48WKWLFlC48Y6TYhSnkqTQinWJx5DBC5tcZHToXiVgikpOnbsyB133MHWrVt1imulvIBeaC7FhqQ02jYMpE4NXUynLDIzMxk/fjxVq1ZlypQpOoGdUl5GWwolyMs3bNybTmftOiqTL7/8kujoaGbOnElOTo5OYKeUF9KkUILth4+TmZWr9yeUIi0tjXvuuYcBAwZQo0YNVq9ezSuvvKJ3fyvlhTQplCAu0ZoE77JQTQolSU5OZvHixTz22GP8/PPPXHHFFU6HpJQ6T3pNoQRxSWk0qlODphfpJHhFHT58mPfff5+///3vhRPYBQUFOR2WUuoCaUuhBBsSj+kkeEUYY1iwYAGRkZE89thjhRPYaUJQqnLQpHAWB9JPczDjDDHadVQoMTGRa665hmHDhhEZGakT2ClVCWn30VnEJRZMgqcjj8CapqJPnz6kpqYya9YsRo0aRZUqek6hVGWjSeEsNiSlUauaH+0aBTodiqPi4+Np2bIl/v7+zJ8/n1atWhEaGup0WEopN9FTvbOIS0yjU4t6+PvoJHg5OTlMmjSJqKiowgns+vTpowlBqUrON494pThxJofth4/77FDUn376iS5dujB+/HgGDx7MX/7yF6dDUkpVEE0Kxdi4N51845uL6syYMYMuXbpw+PBhlixZwkcffUTDhg2dDkspVUE0KRQjLimNKgKXtvCdpFAwJcWll17KXXfdxdatW7npppscjkopVdH0QnMxNiQdo33jOgRUr/y/nhMnTvDYY49RvXp1pk6dSs+ePenZs6fTYSmlHKIthSJy8/LZuDfdJ+5P+OKLL4iOjmb27NkYY3QCO6WUJoWith06wansvEq9qM7Ro0e5++67GThwILVr12bNmjW8/PLLeue2UkqTQlFxSfZNa5W4pXD06FGWLl3Kk08+ycaNG+nWrZvTISmlPIRbk4KIXCMiO0QkXkTGFbP9QRHZKiKbRORrEXF8EHxcUhpNL6pJk0o2Cd6hQ4eYMmUKxhjatGlDUlISzzzzDNWrV3c6NKWUB3FbUhARP2AWMBCIBG4TkcgixTYCMcaYjsBi4EV3xVMWxhjiEo9VqvsTjDHMnz+f9u3b8+STTxIfHw9AvXqVp45KqfLjzpZCFyDeGJNgjMkGPgAGuxYwxqw0xpyyn64FmrkxnlLtTzvNkeNZleb+hD179nD11VcTGxvLxRdfzC+//KIT2CmlSuTOMZdNgX0uz/cDl5dQPhb4T3EbRGQkMBKgRYsW5RXfH2xIqjyL6uTm5tK3b1+OHj3Ka6+9xsiRI3UCO6VUqdyZFIobylLsmEcRuROIAXoXt90YMw+YBxATE+O2cZNxSccIqO5Pu0Z13LULt9u1axetWrXC39+ft956i9atW9O8eXOnw1JKeQl3njruB1yPRs2Ag0ULiUh/YDxwgzEmy43xlCouMY1LW1yEXxXvG5qZk5PDxIkTiY6O5tVXXwXgyiuv1ISglDon7mwprAciRKQlcAAYAtzuWkBELgXmAtcYY5LdGEupMk7nsOPICQZGN3YyjPMSFxdHbGwsmzZtYsiQIdx2221Oh6SU8lJuaykYY3KBscAKYBvwkTFmi4g8IyI32MVeAgKAj0XkZxFZ5q54SrNxbxrGCyfBe+WVV7j88stJTU3l008/5f333yckJMTpsJRSXsqtk/sYY5YDy4u89pTL4/7u3P+52JCUhl8V4ZLmFzkdSpkYYxARYmJiiI2N5cUXX+Sii7wjdqWU56r8M76V0frEY0Q2rkNtD58E7/jx4zz66KPUqFGDadOm0aNHD3r06OF0WEqpSkLHKAI5efn8vC/d44eiLl++nKioKObNm4e/v79OYKeUKneaFICtB49zJiffY68npKamcuedd3LddddRt25dvv/+e1566SWdwE4pVe40KWDNdwQQE+qZM6OmpaXx2Wef8c9//pOffvqJyy8v6R5ApZQ6f57dgV5B4hKP0axeTRrVreF0KIUOHDjAu+++yz/+8Q8iIiJISkrSC8lKKbfz+ZaCMYa4pDSPmSrbGMPrr79OZGQkEyZMYPfu3QCaEJRSFcLnk8K+Y6dJOZHlEYvq7N69m379+jFy5Eg6derEpk2bCA8PdzospZQP8fnuo4JFdTo7fJE5NzeXfv36cezYMebOncvw4cN1AjulVIXz+aSwPjGNwBr+tAkJdGT/O3bsoHXr1vj7+7NgwQJat25Ns2aOziCulPJhPn8quiHpGJ1a1KNKBU+Cl52dzdNPP02HDh2YNWsWAL1799aEoJRylE+3FDJO5bDzSCbXd2xSoftdt24dsbGxbN68mdtvv5077rijQvevlFJn49MthZ/22vcnVOBF5unTp9OtW7fCew/effddGjRoUGH7V0qpkvh0UlifeAz/CpoEr2BKii5dujBixAi2bNnCoEGD3L5fpZQ6Fz7dfRSXlEZUkzrUrObntn1kZGTwyCOPULNmTaZPn0737t3p3r272/anlFIXwmdbCtm5+fyyL53L3Di1xWeffUZkZCRvvPEG1atX1wnslFIez2eTwpaDGWTl5rvl/oSUlBRuv/12brjhBoKCgli7di2TJ0/WCeyUUh7PZ5NCXKJ1kfkyNySFjIwMli9fztNPP01cXBydO3cu930opZQ7+Ow1hbikY7SoX4uQwPKZBG/fvn0sWrSIcePGER4eTlJSEnXr1i2Xz1ZKqYriky0FYwwbymkSvPz8fObMmUNUVBQTJ04snMBOE4JSyhv5ZFJIOnqK1MzsC74/YdeuXfTt25fRo0fTpUsXfv31V53ATinl1Xyy+2h9ojUJ3oWstJabm8tVV11Feno6b775Jvfcc49eSFZKeT2fTAobktKoU8Of8OCAc37vtm3biIiIwN/fn4ULF9K6dWuaNKnYaTKUUspdfLL7KC4pjctCz20SvKysLP75z3/SsWNHXn31VQB69uypCUEpVan4XEsh7WQ28cmZ3HRp0zK/Z+3atcTGxrJ161aGDh3K0KFD3RihUko5x+daChuS7EnwyjjyaOrUqXTv3p0TJ06wfPly3nnnHYKCgtwZolJKOcbnkkJcUhpV/YSLS5kELz8/H4Bu3boxatQoNm/ezMCBAysiRKWUcozPdR9tSDpGVJO61Kha/CR46enpPPTQQ9SqVYuZM2fqBHZKKZ/iUy2FrNw8ftmfcdb5jj755BMiIyNZsGABgYGBOoGdUsrn+FRS2Hwgg+zc/D/MjJqcnMyf//xnbrrpJho2bMi6deuYNGmS3neglPI5PpUUCifBK3KR+fjx43z11Vc899xzrFu3jk6dOjkRnlJKOc6nrinEJaURFlSL4MDq7N27l4ULF/L4448THh7O3r17CQwMdDpEpZRylFtbCiJyjYjsEJF4ERlXzPbqIvKhvf1HEQlzVywFk+BdFlqP2bNnExUVxaRJkwonsNOEoJRSbkwKIuIHzAIGApHAbSISWaRYLJBmjAkHpgGT3RVPQupJjp3MZuVHb3D//ffTrVs3tmzZohPYKaWUC3e2FLoA8caYBGNMNvABMLhImcHAAvvxYqCfuOnq7rqEVACSNqzkrbfeYsWKFYSFhbljV0op5bXceU2hKbDP5fl+4PKzlTHG5IpIBhAEpLoWEpGRwEiAFi1anFcwQQE1uKyhPzPWfEVTna9IKaWK5c6kUNwZf9GB/2UpgzFmHjAPICYm5rxuHrg6qhFXRzU6n7cqpZTPcGf30X6gucvzZsDBs5UREX+gLnDMjTEppZQqgTuTwnogQkRaikg1YAiwrEiZZcDd9uNbgG+M3kaslFKOcVv3kX2NYCywAvAD5htjtojIM0CcMWYZ8CawUETisVoIQ9wVj1JKqdK59eY1Y8xyYHmR155yeXwGuNWdMSillCo7n5rmQimlVMk0KSillCqkSUEppVQhTQpKKaUKibeNABWRFCDpPN/egCJ3S/sArbNv0Dr7hgupc6gxJri0Ql6XFC6EiMQZY2KcjqMiaZ19g9bZN1REnbX7SCmlVCFNCkoppQr5WlKY53QADtA6+wats29we5196pqCUkqpkvlaS0EppVQJNCkopZQqVCmTgohcIyI7RCReRMYVs726iHxob/9RRMIqPsryVYY6PygiW0Vkk4h8LSKhTsRZnkqrs0u5W0TEiIjXD18sS51F5M/233qLiLxX0TGWtzJ8t1uIyEoR2Wh/v691Is7yIiLzRSRZRDafZbuIyAz797FJRDqVawDGmEr1gzVN926gFVAN+AWILFJmDDDHfjwE+NDpuCugzn2AWvbj0b5QZ7tcILAaWAvEOB13BfydI4CNQD37eYjTcVdAnecBo+3HkUCi03FfYJ17AZ2AzWfZfi3wH6yVK7sCP5bn/itjS6ELEG+MSTDGZAMfAIOLlBkMLLAfLwb6iUhxS4N6i1LrbIxZaYw5ZT9di7USnjcry98Z4FngReBMRQbnJmWp8whgljEmDcAYk1zBMZa3stTZAHXsx3X54wqPXsUYs5qSV6AcDLxjLGuBi0SkcXntvzImhabAPpfn++3Xii1jjMkFMoCgConOPcpSZ1exWGca3qzUOovIpUBzY8y/KzIwNyrL37kN0EZE1ojIWhG5psKic4+y1HkCcKeI7Mdav+WBignNMef6//2cuHWRHYcUd8ZfdNxtWcp4kzLXR0TuBGKA3m6NyP1KrLOIVAGmAcMqKqAKUJa/sz9WF9KVWK3B70Qk2hiT7ubY3KUsdb4NeNsYM1VEumGt5hhtjMl3f3iOcOvxqzK2FPYDzV2eN+OPzcnCMiLij9XkLKm55unKUmdEpD8wHrjBGJNVQbG5S2l1DgSigVUikojV97rMyy82l/W7/akxJscYswfYgZUkvFVZ6hwLfARgjPkBqIE1cVxlVab/7+erMiaF9UCEiLQUkWpYF5KXFSmzDLjbfnwL8I2xr+B4qVLrbHelzMVKCN7ezwyl1NkYk2GMaWCMCTPGhGFdR7nBGBPnTLjloizf7U+wBhUgIg2wupMSKjTK8lWWOu8F+gGISHuspJBSoVFWrGXAXfYopK5AhjHmUHl9eKXrPjLG5IrIWGAF1siF+caYLSLyDBBnjFkGvInVxIzHaiEMcS7iC1fGOr8EBAAf29fU9xpjbnAs6AtUxjpXKmWs8wrgahHZCuQB/zDGHHUu6gtTxjo/BLwuIn/H6kYZ5s0neSLyPlb3XwP7Osk/gaoAxpg5WNdNrgXigVPAPeW6fy/+3SmllCpnlbH7SCml1HnSpKCUUqqQJgWllFKFNCkopZQqpElBKaVUIU0KSp0HEfk/EdkmIu86HYtS5UmHpCp1HkRkOzDQvmu4tLJ+xpi8CghLqQumLQWlzpGIzMGaynmZiGSIyEIR+UZEdonICLvMlfYc/+8BvzoasFLnQFsKSp0Hez6lGGAscBPW3Eq1sdYyuBxreonPgeiytCaU8hTaUlDqwn1qjDltjEkFVmKtAQCwThOC8jaaFJS6cEWb2wXPT1Z0IEpdKE0KSl24wSJSQ0SCsCYyW+9wPEqdN00KSl24dVjXD9YCzxpjvHo5SOXb9EKzUhdARCYAmcaYKU7HolR50JaCUkqpQtpSUEopVUhbCkoppQppUlBKKVVIk4JSSqlCmhSUUkoV0qSglFKq0P8DxOGil4YLOW8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ROC')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('DecisionTree(max_depth=3) ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las mtricas Accuracy y ROC AUC. Para ello, se pide medir la performance en cada particin tanto sobre el fold de validacin como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validacin)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validacin)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutacin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.7407</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.7377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.8325</td>\n",
       "      <td>0.6697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8255</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.8248</td>\n",
       "      <td>0.6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.6822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validacin)  AUC ROC (training)  \\\n",
       "Permutacin                                                                   \n",
       "1                         0.8245                 0.6296              0.8200   \n",
       "2                         0.8464                 0.7407              0.8418   \n",
       "3                         0.8406                 0.6875              0.8325   \n",
       "4                         0.8255                 0.6962              0.8248   \n",
       "5                         0.8442                 0.6835              0.8421   \n",
       "\n",
       "             AUC ROC (validacin)  \n",
       "Permutacin                        \n",
       "1                          0.6204  \n",
       "2                          0.7377  \n",
       "3                          0.6697  \n",
       "4                          0.6983  \n",
       "5                          0.6822  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "np.random.seed(SEED) # esto lo agregue para fijar el random state\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "splits = cv.split(X_dev, y_dev)\n",
    "#scores = pd.DataFrame(columns=['accuracies_training','accuracies_validation','aucs_training','aucs_validation'])\n",
    "for train_idxs, val_idxs in splits:\n",
    "    arbol_2_2 = DecisionTreeClassifier(max_depth=3)\n",
    "    arbol_2_2.fit(X_dev.iloc[train_idxs], y_dev.iloc[train_idxs])\n",
    "    y_train = y_dev.iloc[train_idxs]\n",
    "    y_val = y_dev.iloc[val_idxs]\n",
    "    y_train_pred = arbol_2_2.predict(X_dev.iloc[train_idxs])\n",
    "    y_val_pred = arbol_2_2.predict(X_dev.iloc[val_idxs])\n",
    "#    scores = scores.append(pd.Series({\n",
    "#        'accuracies_training': sklearn.metrics.accuracy_score(y_train, y_train_pred),\n",
    "#        'accuracies_validation': sklearn.metrics.accuracy_score(y_val, y_val_pred),\n",
    "#        'aucs_training': sklearn.metrics.roc_auc_score(y_train, y_train_pred),\n",
    "#        'aucs_validation': sklearn.metrics.roc_auc_score(y_val, y_val_pred)\n",
    "#     }), ignore_index=True)\n",
    "    accuracies_training.append(sklearn.metrics.accuracy_score(y_train, y_train_pred))\n",
    "    accuracies_validation.append(sklearn.metrics.accuracy_score(y_val, y_val_pred))\n",
    "    aucs_training.append(sklearn.metrics.roc_auc_score(y_train, y_train_pred))\n",
    "    aucs_validation.append(sklearn.metrics.roc_auc_score(y_val, y_val_pred))\n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutacin\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training     # cambiar por accuracies_training\n",
    "df[\"Accuracy (validacin)\"] = accuracies_validation   # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training      # cambiar por aucs_training\n",
    "df[\"AUC ROC (validacin)\"] = aucs_validation    # cambiar por aucs_validation\n",
    "\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes lneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419484702093398"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_eval,y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar rboles de decisin para cada una de las siguientes combinaciones y completar la segunda tabla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura mxima</th>\n",
       "      <th>Criterio de evaluacin de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validacin)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>0.6965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Informacin</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.6795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Informacin</td>\n",
       "      <td>0.9121</td>\n",
       "      <td>0.5946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Informacin</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura mxima Criterio de evaluacin de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8068   \n",
       "1             5                            Gini                       0.9473   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Informacin                       0.7882   \n",
       "4             5         Ganancia de Informacin                       0.9121   \n",
       "5     Inifinito         Ganancia de Informacin                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validacin)  \n",
       "0                         0.6965  \n",
       "1                         0.6610  \n",
       "2                         0.6888  \n",
       "3                         0.6795  \n",
       "4                         0.5946  \n",
       "5                         0.6425  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "np.random.seed(SEED)\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "#         CODIGO AQUI.\n",
    "        arbol_2_3 = DecisionTreeClassifier(max_depth=altura, criterion=criterio)\n",
    "        arbol_2_3.fit(X_dev, y_dev)    \n",
    "        y_dev_pred = arbol_2_3.predict(X_dev)\n",
    "        y_eval_pred = arbol_2_3.predict(X_eval)\n",
    "        resultados_training.append(sklearn.metrics.roc_auc_score(y_dev, y_dev_pred))\n",
    "        resultados_validation.append(sklearn.metrics.roc_auc_score(y_eval, y_eval_pred))\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura mxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluacin de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Informacin\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validacin)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*EJERCICIO EXTRA: Usar la implementacin de rboles de decisin que realizaron para la gua de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores. *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementacion de mi arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_arbol(instancias, etiquetas,nmax=999999,nlevel=0):\n",
    "    # ALGORITMO RECURSIVO para construccin de un rbol de decisin binario. \n",
    "    # Suponemos que estamos parados en la raiz del rbol y tenemos que decidir cmo construirlo. \n",
    "    nlevel = nlevel + 1\n",
    "    ganancia, pregunta = encontrar_mejor_atributo_y_corte(instancias, etiquetas) \n",
    "    print \"Mejor pregunta \"\n",
    "    print(pregunta)\n",
    "    # Criterio de corte: Hay ganancia?\n",
    "    if ganancia == 0 or nmax == nlevel :\n",
    "        #  Si no hay ganancia en separar, no separamos. \n",
    "        return Hoja(etiquetas)\n",
    "    else: \n",
    "        # Si hay ganancia en partir el conjunto en 2\n",
    "        instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen = partir_segun(pregunta, instancias, etiquetas)\n",
    "        print (\"partio el arbol\")\n",
    "        # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n",
    "\n",
    "        # Paso recursivo (consultar con el computador ms cercano)\n",
    "        sub_arbol_izquierdo = construir_arbol(instancias_cumplen, etiquetas_cumplen,nmax,nlevel)\n",
    "        print \"arbol_izq\"\n",
    "        sub_arbol_derecho   = construir_arbol(instancias_no_cumplen, etiquetas_no_cumplen,nmax,nlevel)\n",
    "        print \"arbol_derecho\"\n",
    "        # los pasos anteriores crean todo lo que necesitemos de sub-rbol izquierdo y sub-rbol derecho\n",
    "        \n",
    "        # slo falta conectarlos con un nodo de decisin:\n",
    "        return Nodo_De_Decision(pregunta, sub_arbol_izquierdo, sub_arbol_derecho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicin de la estructura del rbol. \n",
    "\n",
    "class Hoja:\n",
    "    #  Contiene las cuentas para cada clase (en forma de diccionario)\n",
    "    #  Por ejemplo, {'Si': 1, 'No': 2}\n",
    "    def __init__(self, etiquetas):\n",
    "        self.cuentas = dict(Counter(etiquetas))\n",
    "\n",
    "\n",
    "class Nodo_De_Decision:\n",
    "    # Un Nodo de Decisin contiene preguntas y una referencia al sub-rbol izquierdo y al sub-rbol derecho\n",
    "     \n",
    "    def __init__(self, pregunta, sub_arbol_izquierdo, sub_arbol_derecho):\n",
    "        self.pregunta = pregunta\n",
    "        self.sub_arbol_izquierdo = sub_arbol_izquierdo\n",
    "        self.sub_arbol_derecho = sub_arbol_derecho\n",
    "        \n",
    "        \n",
    "# Definicin de la clase \"Pregunta\"\n",
    "class Pregunta:\n",
    "    def __init__(self, atributo, valor):\n",
    "        self.atributo = atributo\n",
    "        self.valor = valor\n",
    "    \n",
    "    def cumple(self, instancia):\n",
    "        # Devuelve verdadero si la instancia cumple con la pregunta\n",
    "        return instancia[self.atributo] == self.valor ## OJOOOOOO\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Es el valor para {} igual a {}?\".format(self.atributo, self.valor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(etiquetas):\n",
    "    impureza = 0\n",
    "    # COMPLETAR\n",
    "    # gini inicial\n",
    "    pr_pos = etiquetas.count('Si') / len(etiquetas)\n",
    "    pr_neg = etiquetas.count('No') / len(etiquetas)\n",
    "    impureza = 1 - (pr_pos)**2 - (pr_neg)**2\n",
    "    return impureza\n",
    "#etiquetas por instancias\n",
    "def ganancia_gini(etiquetas, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    ganancia_gini = 0\n",
    "    \n",
    "    pr_rama_izq = len(etiquetas_rama_izquierda) / len(etiquetas)\n",
    "    if (len(etiquetas_rama_izquierda) == 0):\n",
    "        gini_rama_izq = 0\n",
    "    else:\n",
    "        pr_pos_rI = etiquetas_rama_izquierda.count('Si') / len(etiquetas_rama_izquierda)\n",
    "        pr_neg_rI = etiquetas_rama_izquierda.count('No') / len(etiquetas_rama_izquierda)\n",
    "        gini_rama_izq = 1 - (pr_pos_rI)**2 - (pr_neg_rI)**2\n",
    "    \n",
    "    # me paro en el sub-arbol izq y agarro la rama der\n",
    "    pr_rama_der = len(etiquetas_rama_derecha) / len(etiquetas)\n",
    "    if (len(etiquetas_rama_derecha)==0):\n",
    "        gini_rama_der = 0\n",
    "    else :    \n",
    "        pr_pos_rD = etiquetas_rama_derecha.count('Si') / len(etiquetas_rama_derecha)\n",
    "        pr_neg_rD = etiquetas_rama_derecha.count('No') / len(etiquetas_rama_derecha)\n",
    "        gini_rama_der = 1 - (pr_pos_rD)**2 - (pr_neg_rD)**2\n",
    "    \n",
    "    gini_subarbol = pr_rama_izq * gini_rama_izq + pr_rama_der * gini_rama_der\n",
    "    \n",
    "    ganancia_gini = gini(etiquetas) - gini_subarbol\n",
    "    \n",
    "    return ganancia_gini\n",
    "\n",
    "partir_cache = {}\n",
    "\n",
    "def partir_segun(pregunta, instancias, etiquetas):\n",
    "    #usamos la representacion en string de pregunta porque es hasheable\n",
    "    pregunta_str = pregunta.__repr__()\n",
    "    #hasheamos las instancias y etiquetas, y las metemos en una tupla\n",
    "    inst_etiq = (np.array(instancias).tostring(),np.array(etiquetas).tostring())\n",
    "    if (pregunta_str in partir_cache):\n",
    "        if inst_etiq in partir_cache[pregunta_str]:\n",
    "            #si ya lo calculamos, devolvemos el resultado almacenado\n",
    "            return partir_cache[pregunta_str][inst_etiq]\n",
    "        \n",
    "    # Esta funcin debe separar instancias y etiquetas segn si cada instancia cumple o no con la pregunta (ver mtodo 'cumple')\n",
    "    # COMPLETAR (recomendamos utilizar mscaras para este punto)\n",
    "    instancias_cumplen = map(lambda inst: pregunta.cumple(inst[1]),instancias.iterrows())\n",
    "    instancias_no_cumplen = map(lambda inst: not(pregunta.cumple(inst[1])),instancias.iterrows())\n",
    "    indices_cumplen = filter(lambda i: instancias_cumplen[i] == True,range(0,len(instancias_cumplen)))\n",
    "    indices_no_cumplen = filter(lambda i: instancias_cumplen[i] == False,range(0,len(instancias_cumplen)))\n",
    "    \n",
    "    etiquetas_cumplen = map(lambda ind: etiquetas[ind], indices_cumplen)\n",
    "    etiquetas_no_cumplen = map(lambda ind: etiquetas[ind], indices_no_cumplen)\n",
    "    \n",
    "    instancias_cumplen = instancias.iloc[indices_cumplen]\n",
    "    instancias_no_cumplen = instancias.iloc[indices_no_cumplen]\n",
    "    \n",
    "    if not (pregunta_str in partir_cache):\n",
    "        partir_cache[pregunta_str] = {}\n",
    "        \n",
    "    #cacheamos el resultado en partir_cache\n",
    "    partir_cache[pregunta_str][inst_etiq] = instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen\n",
    "    \n",
    "    #instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen = None, None, None, None\n",
    "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mejor_atributo_y_corte(instancias, etiquetas):\n",
    "    max_ganancia = 0\n",
    "    mejor_pregunta = None\n",
    "    #Para evitar partir segun preguntas repetidas \n",
    "    # (porque el algoritmo recorre celdas en vez de valores posibles) \n",
    "    preguntas_hechas = set([])\n",
    "    for columna in instancias.columns:\n",
    "        for valor in set(instancias[columna]):\n",
    "            # Probando corte para atributo y valor\n",
    "            pregunta = Pregunta(columna, valor)\n",
    "            if (pregunta.__repr__() in preguntas_hechas):\n",
    "                continue\n",
    "#             print(pregunta)\n",
    "            _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun(pregunta, instancias, etiquetas)\n",
    "            #etiquetas por instancias  \n",
    "            ganancia = ganancia_gini(etiquetas, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "            \n",
    "            if ganancia > max_ganancia:\n",
    "                max_ganancia = ganancia\n",
    "                mejor_pregunta = pregunta\n",
    "            preguntas_hechas.add(pregunta.__repr__())\n",
    "            \n",
    "    return max_ganancia, mejor_pregunta\n",
    "\n",
    "\n",
    "def imprimir_arbol(arbol, spacing=\"\"):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        print (spacing + \"Hoja:\", arbol.cuentas)\n",
    "        return\n",
    "\n",
    "    print (spacing + str(arbol.pregunta))\n",
    "\n",
    "    print (spacing + '--> True:')\n",
    "    imprimir_arbol(arbol.sub_arbol_izquierdo, spacing + \"  \")\n",
    "\n",
    "    print (spacing + '--> False:')\n",
    "    imprimir_arbol(arbol.sub_arbol_derecho, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = construir_arbol(x_dev, y_dev)\n",
    "imprimir_arbol(arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protocolo sklearn\n",
    "def elegir_maximo(cuentas):\n",
    "    #Completar\n",
    "    si = 0\n",
    "    no = 0\n",
    "    if \"Si\" in cuentas:\n",
    "        si = cuentas[\"Si\"]\n",
    "    if \"No\" in cuentas:\n",
    "        no = cuentas[\"No\"]\n",
    "    if si > no:\n",
    "        return \"Si\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "def predecir(arbol, x_t):\n",
    "    # COMPLETAR\n",
    "    # dada instancia nueva, el predictor tiene q recorrer el arbol y decir Si o No\n",
    "    if isinstance(arbol, Hoja):\n",
    "        return elegir_maximo(arbol.cuentas)\n",
    "    \n",
    "    if (arbol.pregunta.cumple(x_t)):\n",
    "        return predecir(arbol.sub_arbol_izquierdo,x_t)\n",
    "    else:\n",
    "        return predecir(arbol.sub_arbol_derecho,x_t)\n",
    "    \n",
    "            \n",
    "class MiClasificadorArbol(): \n",
    "    def __init__(self,n,nmax=-1):\n",
    "        self.arbol = None\n",
    "        self.columnas = range(0,n)\n",
    "        self.nmax = nmax\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        if self.nmax > 0:\n",
    "            self.arbol = construir_arbol(pd.DataFrame(X_train, columns=self.columnas), y_train,nmax=self.nmax)\n",
    "        else: \n",
    "            self.arbol = construir_arbol(pd.DataFrame(X_train, columns=self.columnas), y_train)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x_t in X_test:\n",
    "            x_t_df = pd.DataFrame([x_t], columns=self.columnas).iloc[0]\n",
    "            prediction = predecir(self.arbol, x_t_df) \n",
    "#             print(x_t, \"prediccin ->\", prediction)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        \n",
    "        accuracy = sum(y_i == y_j for (y_i, y_j) in zip(y_pred, y_test)) / len(y_test)\n",
    "        return accuracy\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(column,column_name,nlabels):\n",
    "    ordered_column = np.copy(column)\n",
    "    ordered_column.sort()\n",
    "    clases = {}\n",
    "    #separa uniformemente en el dominio de valores\n",
    "    delimitadores = np.linspace(ordered_column[0],ordered_column[-1],nlabels)\n",
    "    delim_string = [\"\"]*(len(delimitadores)+2)\n",
    "    i = 0  \n",
    "    for value in ordered_column:\n",
    "#         print \"value : %.2f, i: %.2f\" %(value,i)\n",
    "        if (value < delimitadores[i]):\n",
    "            clases[value] = i\n",
    "        else:\n",
    "            if (i == 0):\n",
    "                delim_string[i] = \"%s <= %.2f\" % (column_name,value) \n",
    "                old_value = value\n",
    "            else:\n",
    "                delim_string[i] = \"%.2f <= %s < %.2f\" % (old_value,column_name,value)\n",
    "            old_value = value\n",
    "            i = i + 1\n",
    "            clases[value] = i\n",
    "    \n",
    "    if (i > 0):\n",
    "        delim_string[i] = \"%i <= %s\" % (old_value,column_name)\n",
    "                \n",
    "    return map(lambda x: delim_string[clases[x]],column)\n",
    "\n",
    "# s = range(0,100)\n",
    "# shuffle(s)\n",
    "# partition(s,\"x\",10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>...</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.17 &lt;= x_0 &lt; -0.09</td>\n",
       "      <td>-2.46 &lt;= x_1 &lt; 0.18</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>-2.43 &lt;= x_100 &lt; 0.16</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-2.67 &lt;= x_102 &lt; -0.08</td>\n",
       "      <td>-2.75 &lt;= x_103 &lt; -0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24 &lt;= x_93 &lt; 2.79</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>0.14 &lt;= x_95 &lt; 3.63</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>0.12 &lt;= x_97 &lt; 3.31</td>\n",
       "      <td>-2.58 &lt;= x_98 &lt; 0.36</td>\n",
       "      <td>-3.27 &lt;= x_99 &lt; -0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.17 &lt;= x_0 &lt; -0.09</td>\n",
       "      <td>0.18 &lt;= x_1 &lt; 2.79</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>-2.43 &lt;= x_100 &lt; 0.16</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-2.75 &lt;= x_103 &lt; -0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28 &lt;= x_93 &lt; -0.24</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>0.14 &lt;= x_95 &lt; 3.63</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>-3.08 &lt;= x_97 &lt; 0.12</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-0.20 &lt;= x_99 &lt; 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.09 &lt;= x_0 &lt; 2.97</td>\n",
       "      <td>0.18 &lt;= x_1 &lt; 2.79</td>\n",
       "      <td>-3.53 &lt;= x_10 &lt; -0.46</td>\n",
       "      <td>0.16 &lt;= x_100 &lt; 2.75</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-2.67 &lt;= x_102 &lt; -0.08</td>\n",
       "      <td>-2.75 &lt;= x_103 &lt; -0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28 &lt;= x_93 &lt; -0.24</td>\n",
       "      <td>0.79 &lt;= x_94 &lt; 4.07</td>\n",
       "      <td>0.14 &lt;= x_95 &lt; 3.63</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>0.12 &lt;= x_97 &lt; 3.31</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-0.20 &lt;= x_99 &lt; 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.09 &lt;= x_0 &lt; 2.97</td>\n",
       "      <td>-2.46 &lt;= x_1 &lt; 0.18</td>\n",
       "      <td>-3.53 &lt;= x_10 &lt; -0.46</td>\n",
       "      <td>0.16 &lt;= x_100 &lt; 2.75</td>\n",
       "      <td>-3.60 &lt;= x_101 &lt; -0.29</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-0.09 &lt;= x_103 &lt; 2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28 &lt;= x_93 &lt; -0.24</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>0.14 &lt;= x_95 &lt; 3.63</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>0.12 &lt;= x_97 &lt; 3.31</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-3.27 &lt;= x_99 &lt; -0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.09 &lt;= x_0 &lt; 2.97</td>\n",
       "      <td>-2.46 &lt;= x_1 &lt; 0.18</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>0.16 &lt;= x_100 &lt; 2.75</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-2.67 &lt;= x_102 &lt; -0.08</td>\n",
       "      <td>-0.09 &lt;= x_103 &lt; 2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24 &lt;= x_93 &lt; 2.79</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>-3.36 &lt;= x_95 &lt; 0.14</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>0.12 &lt;= x_97 &lt; 3.31</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-3.27 &lt;= x_99 &lt; -0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-3.17 &lt;= x_0 &lt; -0.09</td>\n",
       "      <td>0.18 &lt;= x_1 &lt; 2.79</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>-2.43 &lt;= x_100 &lt; 0.16</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-2.75 &lt;= x_103 &lt; -0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24 &lt;= x_93 &lt; 2.79</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>-3.36 &lt;= x_95 &lt; 0.14</td>\n",
       "      <td>0.17 &lt;= x_96 &lt; 3.19</td>\n",
       "      <td>-3.08 &lt;= x_97 &lt; 0.12</td>\n",
       "      <td>-2.58 &lt;= x_98 &lt; 0.36</td>\n",
       "      <td>-0.20 &lt;= x_99 &lt; 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-0.09 &lt;= x_0 &lt; 2.97</td>\n",
       "      <td>0.18 &lt;= x_1 &lt; 2.79</td>\n",
       "      <td>-3.53 &lt;= x_10 &lt; -0.46</td>\n",
       "      <td>-2.43 &lt;= x_100 &lt; 0.16</td>\n",
       "      <td>-3.60 &lt;= x_101 &lt; -0.29</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-0.09 &lt;= x_103 &lt; 2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24 &lt;= x_93 &lt; 2.79</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>-3.36 &lt;= x_95 &lt; 0.14</td>\n",
       "      <td>0.17 &lt;= x_96 &lt; 3.19</td>\n",
       "      <td>0.12 &lt;= x_97 &lt; 3.31</td>\n",
       "      <td>-2.58 &lt;= x_98 &lt; 0.36</td>\n",
       "      <td>-0.20 &lt;= x_99 &lt; 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-3.17 &lt;= x_0 &lt; -0.09</td>\n",
       "      <td>-2.46 &lt;= x_1 &lt; 0.18</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>0.16 &lt;= x_100 &lt; 2.75</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-2.75 &lt;= x_103 &lt; -0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24 &lt;= x_93 &lt; 2.79</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>0.14 &lt;= x_95 &lt; 3.63</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>-3.08 &lt;= x_97 &lt; 0.12</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-0.20 &lt;= x_99 &lt; 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-3.17 &lt;= x_0 &lt; -0.09</td>\n",
       "      <td>0.18 &lt;= x_1 &lt; 2.79</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>-2.43 &lt;= x_100 &lt; 0.16</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-0.09 &lt;= x_103 &lt; 2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28 &lt;= x_93 &lt; -0.24</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>-3.36 &lt;= x_95 &lt; 0.14</td>\n",
       "      <td>0.17 &lt;= x_96 &lt; 3.19</td>\n",
       "      <td>-3.08 &lt;= x_97 &lt; 0.12</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-0.20 &lt;= x_99 &lt; 2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-3.17 &lt;= x_0 &lt; -0.09</td>\n",
       "      <td>-2.46 &lt;= x_1 &lt; 0.18</td>\n",
       "      <td>-0.46 &lt;= x_10 &lt; 2.54</td>\n",
       "      <td>-2.43 &lt;= x_100 &lt; 0.16</td>\n",
       "      <td>-0.29 &lt;= x_101 &lt; 3.03</td>\n",
       "      <td>-0.08 &lt;= x_102 &lt; 2.49</td>\n",
       "      <td>-0.09 &lt;= x_103 &lt; 2.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28 &lt;= x_93 &lt; -0.24</td>\n",
       "      <td>-2.55 &lt;= x_94 &lt; 0.79</td>\n",
       "      <td>0.14 &lt;= x_95 &lt; 3.63</td>\n",
       "      <td>-2.87 &lt;= x_96 &lt; 0.17</td>\n",
       "      <td>0.12 &lt;= x_97 &lt; 3.31</td>\n",
       "      <td>0.36 &lt;= x_98 &lt; 3.29</td>\n",
       "      <td>-3.27 &lt;= x_99 &lt; -0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      x_0                  x_1                   x_10  \\\n",
       "0    -3.17 <= x_0 < -0.09  -2.46 <= x_1 < 0.18   -0.46 <= x_10 < 2.54   \n",
       "1    -3.17 <= x_0 < -0.09   0.18 <= x_1 < 2.79   -0.46 <= x_10 < 2.54   \n",
       "2     -0.09 <= x_0 < 2.97   0.18 <= x_1 < 2.79  -3.53 <= x_10 < -0.46   \n",
       "3     -0.09 <= x_0 < 2.97  -2.46 <= x_1 < 0.18  -3.53 <= x_10 < -0.46   \n",
       "4     -0.09 <= x_0 < 2.97  -2.46 <= x_1 < 0.18   -0.46 <= x_10 < 2.54   \n",
       "..                    ...                  ...                    ...   \n",
       "395  -3.17 <= x_0 < -0.09   0.18 <= x_1 < 2.79   -0.46 <= x_10 < 2.54   \n",
       "396   -0.09 <= x_0 < 2.97   0.18 <= x_1 < 2.79  -3.53 <= x_10 < -0.46   \n",
       "397  -3.17 <= x_0 < -0.09  -2.46 <= x_1 < 0.18   -0.46 <= x_10 < 2.54   \n",
       "398  -3.17 <= x_0 < -0.09   0.18 <= x_1 < 2.79   -0.46 <= x_10 < 2.54   \n",
       "399  -3.17 <= x_0 < -0.09  -2.46 <= x_1 < 0.18   -0.46 <= x_10 < 2.54   \n",
       "\n",
       "                     x_100                   x_101                   x_102  \\\n",
       "0    -2.43 <= x_100 < 0.16   -0.29 <= x_101 < 3.03  -2.67 <= x_102 < -0.08   \n",
       "1    -2.43 <= x_100 < 0.16   -0.29 <= x_101 < 3.03   -0.08 <= x_102 < 2.49   \n",
       "2     0.16 <= x_100 < 2.75   -0.29 <= x_101 < 3.03  -2.67 <= x_102 < -0.08   \n",
       "3     0.16 <= x_100 < 2.75  -3.60 <= x_101 < -0.29   -0.08 <= x_102 < 2.49   \n",
       "4     0.16 <= x_100 < 2.75   -0.29 <= x_101 < 3.03  -2.67 <= x_102 < -0.08   \n",
       "..                     ...                     ...                     ...   \n",
       "395  -2.43 <= x_100 < 0.16   -0.29 <= x_101 < 3.03   -0.08 <= x_102 < 2.49   \n",
       "396  -2.43 <= x_100 < 0.16  -3.60 <= x_101 < -0.29   -0.08 <= x_102 < 2.49   \n",
       "397   0.16 <= x_100 < 2.75   -0.29 <= x_101 < 3.03   -0.08 <= x_102 < 2.49   \n",
       "398  -2.43 <= x_100 < 0.16   -0.29 <= x_101 < 3.03   -0.08 <= x_102 < 2.49   \n",
       "399  -2.43 <= x_100 < 0.16   -0.29 <= x_101 < 3.03   -0.08 <= x_102 < 2.49   \n",
       "\n",
       "                      x_103          ...                             x_93  \\\n",
       "0    -2.75 <= x_103 < -0.09          ...             -0.24 <= x_93 < 2.79   \n",
       "1    -2.75 <= x_103 < -0.09          ...            -3.28 <= x_93 < -0.24   \n",
       "2    -2.75 <= x_103 < -0.09          ...            -3.28 <= x_93 < -0.24   \n",
       "3     -0.09 <= x_103 < 2.54          ...            -3.28 <= x_93 < -0.24   \n",
       "4     -0.09 <= x_103 < 2.54          ...             -0.24 <= x_93 < 2.79   \n",
       "..                      ...          ...                              ...   \n",
       "395  -2.75 <= x_103 < -0.09          ...             -0.24 <= x_93 < 2.79   \n",
       "396   -0.09 <= x_103 < 2.54          ...             -0.24 <= x_93 < 2.79   \n",
       "397  -2.75 <= x_103 < -0.09          ...             -0.24 <= x_93 < 2.79   \n",
       "398   -0.09 <= x_103 < 2.54          ...            -3.28 <= x_93 < -0.24   \n",
       "399   -0.09 <= x_103 < 2.54          ...            -3.28 <= x_93 < -0.24   \n",
       "\n",
       "                     x_94                  x_95                  x_96  \\\n",
       "0    -2.55 <= x_94 < 0.79   0.14 <= x_95 < 3.63  -2.87 <= x_96 < 0.17   \n",
       "1    -2.55 <= x_94 < 0.79   0.14 <= x_95 < 3.63  -2.87 <= x_96 < 0.17   \n",
       "2     0.79 <= x_94 < 4.07   0.14 <= x_95 < 3.63  -2.87 <= x_96 < 0.17   \n",
       "3    -2.55 <= x_94 < 0.79   0.14 <= x_95 < 3.63  -2.87 <= x_96 < 0.17   \n",
       "4    -2.55 <= x_94 < 0.79  -3.36 <= x_95 < 0.14  -2.87 <= x_96 < 0.17   \n",
       "..                    ...                   ...                   ...   \n",
       "395  -2.55 <= x_94 < 0.79  -3.36 <= x_95 < 0.14   0.17 <= x_96 < 3.19   \n",
       "396  -2.55 <= x_94 < 0.79  -3.36 <= x_95 < 0.14   0.17 <= x_96 < 3.19   \n",
       "397  -2.55 <= x_94 < 0.79   0.14 <= x_95 < 3.63  -2.87 <= x_96 < 0.17   \n",
       "398  -2.55 <= x_94 < 0.79  -3.36 <= x_95 < 0.14   0.17 <= x_96 < 3.19   \n",
       "399  -2.55 <= x_94 < 0.79   0.14 <= x_95 < 3.63  -2.87 <= x_96 < 0.17   \n",
       "\n",
       "                     x_97                  x_98                   x_99  \n",
       "0     0.12 <= x_97 < 3.31  -2.58 <= x_98 < 0.36  -3.27 <= x_99 < -0.20  \n",
       "1    -3.08 <= x_97 < 0.12   0.36 <= x_98 < 3.29   -0.20 <= x_99 < 2.87  \n",
       "2     0.12 <= x_97 < 3.31   0.36 <= x_98 < 3.29   -0.20 <= x_99 < 2.87  \n",
       "3     0.12 <= x_97 < 3.31   0.36 <= x_98 < 3.29  -3.27 <= x_99 < -0.20  \n",
       "4     0.12 <= x_97 < 3.31   0.36 <= x_98 < 3.29  -3.27 <= x_99 < -0.20  \n",
       "..                    ...                   ...                    ...  \n",
       "395  -3.08 <= x_97 < 0.12  -2.58 <= x_98 < 0.36   -0.20 <= x_99 < 2.87  \n",
       "396   0.12 <= x_97 < 3.31  -2.58 <= x_98 < 0.36   -0.20 <= x_99 < 2.87  \n",
       "397  -3.08 <= x_97 < 0.12   0.36 <= x_98 < 3.29   -0.20 <= x_99 < 2.87  \n",
       "398  -3.08 <= x_97 < 0.12   0.36 <= x_98 < 3.29   -0.20 <= x_99 < 2.87  \n",
       "399   0.12 <= x_97 < 3.31   0.36 <= x_98 < 3.29  -3.27 <= x_99 < -0.20  \n",
       "\n",
       "[400 rows x 200 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "i = 0\n",
    "for column in X_dev.columns:\n",
    "    column_name = \"x_%s\" % column\n",
    "    d[column_name] = partition(np.array(X_dev[column]),column_name,3)\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Si</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0    Si\n",
       "1    No\n",
       "2    Si\n",
       "3    No\n",
       "4    Si\n",
       "..   ..\n",
       "395  No\n",
       "396  Si\n",
       "397  Si\n",
       "398  Si\n",
       "399  Si\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def si_o_no(x):\n",
    "    if (x==1):\n",
    "        return \"Si\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "y_sino = map(si_o_no,np.array(y_dev))\n",
    "\n",
    "df_y = pd.DataFrame(data=y_sino)\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.indexing._iLocIndexer at 0x7f8a5b602208>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos la implementacin del rbol con la interfaz de sklearn y recibiendo variables continuas. Reproducimos la tabla de los valores obtenidos de accuracy para diferentes profundidas de rbol siempre utilizando como criterio de corte la Ganancia Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-9a9fe222c195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0marbol_extra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiClasificadorArbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0marbol_extra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-d56e28c44a77>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnmax\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruir_arbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumnas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruir_arbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumnas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b7a52996f1d1>\u001b[0m in \u001b[0;36mconstruir_arbol\u001b[0;34m(instancias, etiquetas, nmax, nlevel)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Suponemos que estamos parados en la raiz del rbol y tenemos que decidir cmo construirlo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mganancia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpregunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencontrar_mejor_atributo_y_corte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstancias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Mejor pregunta \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpregunta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2a96293d2ced>\u001b[0m in \u001b[0;36mencontrar_mejor_atributo_y_corte\u001b[0;34m(instancias, etiquetas)\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#             print(pregunta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_rama_izquierda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_rama_derecha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartir_segun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpregunta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstancias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m#etiquetas por instancias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mganancia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mganancia_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metiquetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_rama_izquierda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_rama_derecha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a1e02a53b6d9>\u001b[0m in \u001b[0;36mpartir_segun\u001b[0;34m(pregunta, instancias, etiquetas)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0metiquetas_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_cumplen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0metiquetas_no_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_no_cumplen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0minstancias_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstancias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_cumplen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a1e02a53b6d9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0metiquetas_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_cumplen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0metiquetas_no_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_no_cumplen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0minstancias_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstancias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_cumplen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stella/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stella/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stella/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stella/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stella/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "##### CON CV (tal cual ej 2), no me anda #######\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "splits = cv.split(np.array(df), y_sino)\n",
    "\n",
    "for train_idxs, val_idxs in splits:\n",
    "    arbol_extra = MiClasificadorArbol(200,3)\n",
    "    arbol_extra.fit(df.iloc[train_idxs], df_y.iloc[train_idxs])\n",
    "    y_train = df_y.iloc[train_idxs]\n",
    "    y_val = df_y.iloc[val_idxs]\n",
    "    y_train_pred = arbol_extra.predict(df.iloc[train_idxs])\n",
    "    y_val_pred = arbol_extra.predict(df.iloc[val_idxs])\n",
    "\n",
    "    accuracies_training.append(sklearn.metrics.accuracy_score(y_train, y_train_pred))\n",
    "    accuracies_validation.append(sklearn.metrics.accuracy_score(y_val, y_val_pred))\n",
    "    aucs_training.append(sklearn.metrics.roc_auc_score(y_train, y_train_pred))\n",
    "    aucs_validation.append(sklearn.metrics.roc_auc_score(y_val, y_val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor pregunta \n",
      "Es el valor para 82 igual a -3.45 <= x_172 < -0.24?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 6 igual a -2.75 <= x_103 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 158 igual a -3.34 <= x_61 < -0.37?\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 38 igual a -3.08 <= x_132 < 0.02?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 67 igual a -0.34 <= x_159 < 2.59?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 120 igual a -2.86 <= x_27 < 0.02?\n",
      "arbol_derecho\n",
      "arbol_derecho\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7175]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "\n",
    "#clf = GridSearchCV(MiClasificadorArbol(200,3), cv=5)\n",
    "clf = MiClasificadorArbol(200,3)\n",
    "# Tomar en cuenta que sklearn espera numpy arrays:\n",
    "clf.fit(np.array(df), y_sino)\n",
    "acc = [clf.score(np.array(df), y_sino)]\n",
    "display(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor pregunta \n",
      "Es el valor para 82 igual a -3.45 <= x_172 < -0.24?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 6 igual a -2.75 <= x_103 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 138 igual a -0.12 <= x_43 < 2.73?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 176 igual a -3.16 <= x_78 < -0.13?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 9 igual a 0.41 <= x_106 < 3.53?\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 62 igual a 3 <= x_154?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 81 igual a 2 <= x_171?\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 158 igual a -3.34 <= x_61 < -0.37?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 127 igual a -2.56 <= x_33 < 0.71?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 64 igual a 2 <= x_156?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 83 igual a -0.04 <= x_173 < 2.82?\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 38 igual a -3.08 <= x_132 < 0.02?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 67 igual a -0.34 <= x_159 < 2.59?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 54 igual a -3.28 <= x_147 < -0.28?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 112 igual a -2.88 <= x_2 < -0.18?\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 109 igual a 0.38 <= x_197 < 3.18?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 169 igual a -2.73 <= x_71 < -0.10?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 103 igual a -0.42 <= x_191 < 2.92?\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 120 igual a -2.86 <= x_27 < 0.02?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 153 igual a -2.67 <= x_57 < 0.10?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 103 igual a -0.42 <= x_191 < 2.92?\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 122 igual a -2.38 <= x_29 < 0.28?\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 3 igual a 2 <= x_100?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 63 igual a 3 <= x_155?\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7175, 0.8375]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "clf = MiClasificadorArbol(200,5)\n",
    "\n",
    "# Tomar en cuenta que sklearn espera numpy arrays:\n",
    "clf.fit(np.array(df), y_sino)\n",
    "acc.append(clf.score(np.array(df), y_sino))\n",
    "display(acc)\n",
    "\n",
    "#cross_val_score(clf, np.array(df), y_sino, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor pregunta \n",
      "Es el valor para 82 igual a -3.45 <= x_172 < -0.24?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 6 igual a -2.75 <= x_103 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 138 igual a -0.12 <= x_43 < 2.73?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 176 igual a -3.16 <= x_78 < -0.13?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 10 igual a -2.78 <= x_107 < -0.10?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 9 igual a 0.41 <= x_106 < 3.53?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 192 igual a -2.79 <= x_92 < 0.14?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 105 igual a 0.09 <= x_193 < 3.10?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 123 igual a 2 <= x_3?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 196 igual a 0.17 <= x_96 < 3.19?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 0 igual a -3.17 <= x_0 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 62 igual a 3 <= x_154?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 81 igual a 2 <= x_171?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 163 igual a 2 <= x_66?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 158 igual a -3.34 <= x_61 < -0.37?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 127 igual a -2.56 <= x_33 < 0.71?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 64 igual a 2 <= x_156?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 2 igual a -0.46 <= x_10 < 2.54?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 0 igual a -3.17 <= x_0 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 83 igual a -0.04 <= x_173 < 2.82?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 0 igual a 2 <= x_0?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 38 igual a -3.08 <= x_132 < 0.02?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 67 igual a -0.34 <= x_159 < 2.59?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 88 igual a -0.02 <= x_178 < 2.87?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 54 igual a -3.28 <= x_147 < -0.28?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 69 igual a -3.57 <= x_160 < -0.40?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 17 igual a 0.11 <= x_113 < 3.01?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 197 igual a 3 <= x_97?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 56 igual a -3.18 <= x_149 < -0.18?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 34 igual a -0.17 <= x_129 < 2.30?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 112 igual a -2.88 <= x_2 < -0.18?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 19 igual a -3.06 <= x_115 < 0.16?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 48 igual a -2.63 <= x_141 < -0.01?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 5 igual a -2.67 <= x_102 < -0.08?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 59 igual a -3.27 <= x_151 < 0.03?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 1 igual a 0.18 <= x_1 < 2.79?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 59 igual a 3 <= x_151?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 92 igual a -0.34 <= x_181 < 2.82?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 1 igual a 0.18 <= x_1 < 2.79?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 109 igual a 0.38 <= x_197 < 3.18?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 169 igual a -2.73 <= x_71 < -0.10?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 62 igual a 0.16 <= x_154 < 3.13?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 0 igual a -3.17 <= x_0 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 103 igual a -0.42 <= x_191 < 2.92?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 2 igual a -0.46 <= x_10 < 2.54?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 120 igual a -2.86 <= x_27 < 0.02?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 153 igual a -2.67 <= x_57 < 0.10?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 103 igual a -0.42 <= x_191 < 2.92?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 107 igual a -2.52 <= x_195 < 0.20?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 122 igual a -2.38 <= x_29 < 0.28?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 0 igual a -3.17 <= x_0 < -0.09?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 3 igual a 2 <= x_100?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 63 igual a 3 <= x_155?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 83 igual a 2 <= x_173?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 102 igual a 0.32 <= x_190 < 2.92?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 5 igual a -2.67 <= x_102 < -0.08?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "Es el valor para 19 igual a -3.06 <= x_115 < 0.16?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 80 igual a -2.56 <= x_170 < 0.19?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "Es el valor para 2 igual a -3.53 <= x_10 < -0.46?\n",
      "partio el arbol\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_izq\n",
      "Mejor pregunta \n",
      "None\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n",
      "arbol_derecho\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7175, 0.8375, 1.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "clf = MiClasificadorArbol(200)\n",
    "\n",
    "# Tomar en cuenta que sklearn espera numpy arrays:\n",
    "clf.fit(np.array(df), y_sino)\n",
    "acc.append(clf.score(np.array(df), y_sino))\n",
    "display(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 3 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura mxima</th>\n",
       "      <th>Criterio de corte</th>\n",
       "      <th>Accuracy (validacin)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura mxima Criterio de corte  Accuracy (validacin)\n",
       "0             3              Gini                 0.7175\n",
       "1             5              Gini                 0.8375\n",
       "2     Inifinito              Gini                 1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(index=range(0,3))\n",
    "\n",
    "df2[\"Altura mxima\"] = [3, 5, \"Inifinito\"]\n",
    "df2[\"Criterio de corte\"] = [\"Gini\"] * 3\n",
    "#df2[\"Accuracy (training)\"] = acc #resultados_training # reemplazar por resultados_training\n",
    "df2[\"Accuracy (validacin)\"] = acc #resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 3 </h3>\"))\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
